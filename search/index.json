[{"content":"docker初步认识 常见命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #镜像相关 docker search #检索 docker images #列表 docker pull\t#下载 docker rmi\t#删除 #容器相关 docker run\t#运行 docker ps\t#查看 docker stop #停止 docker start #启动 docker restart #重启 docker stats #状态 docker logs\t#日志 docker exec #进入 docker rm #删除 run细节 1 2 3 4 docker run -d --name mynginx -p 80:80 nginx -d 后台启动 --name xxx 声明容器名字xxx -p 80:88 端口映射 在不同容器中88可以重复 保存镜像 1 2 3 docker commit\t#提交 docker save\t#保存 docker load\t#加载 分享社区 1 2 3 docker login\t#登陆 docker tag\t#命名 docker push\t#推送 数据存储与网络 目录挂载 docker允许将内部目录挂载到宿主机某一目录下\n1 2 3 docker run -d -p 80:80 -v /app/nghtml:/usr/share/nginx/html --name mynginx nginx -v 宿主机目录：容器内目录 卷映射 当内部有文件时，进行目录挂载会将内部文件重新从外部进行初始化，这样内部文件就会被外部进行覆盖，如果内部本身有文件，而外部目录无文件时，会导致内部文件被覆盖丢失\n这时我们采用卷映射\n1 2 -v ngconf:/etc/nginx 卷名 ngconf docker 默认将目录放在\n1 /var/lib/docker/volumes/\u0026lt;volume-name\u0026gt; 卷操作\n1 2 3 4 docker volume ls\t列出卷 docker volume create volume-name\t创建卷 docker volume inspect volume-name\t查看卷的详情 注意：删除容器时，卷不会跟随删除 自定义网络 查看容器的细节\n1 docker container inspect container-name 容器在内部有内部网络，docker为每个容器分配唯一ip，使用容器ip+容器端口可以互相访问，但ip由于各种原因可能会变化，docker0默认不支持主机域名，此时我们可以创建自定义网络，容器名也就是稳定域名\n1 2 docker network ls docker network create network-name 创建在自定义网络上生成的容器\n1 2 docker run -d -p 80:80 --name mynginx --network network-name nginx 同一自定义网络下，彼此容器进行访问时，通过域名进行访问，域名即容器名\n1 curl http://mynginx:80 docker应用实现 如何启动一个容器？ 网络相关。考虑端口，是否需要暴露端口让外界访问，加入自定义网络 存储相关。容器是否有什么配置文件或者数据需要挂载在外面方便修改或者防止丢失 环境变量。看官方文档是否需要添加环境变量 Redis主从集群 主机实现：\n1 2 3 4 5 6 docker run -d -p 6379:6379 \\ -v /app/rd1:/bitnami/redis/date \\ -e REDIS_REPLICATION_MODE=master \\ -e REDIS_PASSWORD=123456 \\ --network mynet --name redis01 \\ bitnami/redis 从机实现：\n1 2 3 4 5 6 7 8 9 docker run -d -p 6380:6379 \\ -v /app/rd2:/bitnami/redis/date \\ -e REDIS_REPLICATION_MODE=slave \\ -e REDIS_MASTER_HOST=redis01 -e REDIS_MASTER_PORT_NUMBER=6379 \\ -e REDIS_MASTER_PASSWORD=123456 \\ -e REDIS_PASSWORD=123456 \\ --network mynet --name redis02 \\ bitnami/redis MySQL实例 1 2 3 4 5 6 docker run -d -p 3306:3306 \\ -v /app/myconf:/etc/mysql/conf.d \\ -v /app/mydata:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD=123456 \\ --name mysql \\ mysql:8.0.37-debian docker-compose文件 1 2 3 4 5 docker compose up -d\t上线 docker compose down\t下线 docker compose start x1 x2\t启动 docker compose start x1 x2\t停止 docker compose scale x2=3\t扩容 顶级元素：\nname\t名字 services 服务 networks 网络 volumes 卷 configs 配置 secrets 密钥 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 name: myblog services: mysql: container_name: mysql image: mysql:8.0 ports: - \u0026#34;3306:3306\u0026#34; environment: - MYSQL_ROOT_PASSWORD=123456 - MYSQL_DATABASE=wordpress volumes: - mysql-data:/var/lib/mysql - /app/myconf:/etc/mysql/conf.d restart: always networks: - blog wordpress: container_name: wordpress image: wordpress:latest ports: - \u0026#34;8080:80\u0026#34; environment: - WORDPRESS_DB_HOST=mysql - WORDPRESS_DB_USER=root - WORDPRESS_DB_PASSWORD=123456 - WORDPRESS_DB_NAME=wordpress volumes: - wordpress:var/www/html restart: always networks: - blog depends_on: - mysql volumes: mysql-data: wordpress: networks: blog: 注意：卷映射时要在顶部元素声明\ndockerfile文件 1 2 3 4 5 6 7 FROM alpine WORKDIR /Initial COPY ./target/project-user . COPY ./config/config-docker.yaml . RUN mkdir config \u0026amp;\u0026amp; mv config-docker.yaml config/config.yaml EXPOSE 8080 8881 ENTRYPOINT [\u0026#34;./project-user\u0026#34;] 1 docker build -f dockerfile -t project-user:latest 通过下面文件将go项目编译成exe文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 chcp 65001 @echo off :loop @echo off\u0026amp;amp;color 0A cls echo, echo 请选择要编译的系统环境： echo, echo 1. Windows_amd64 echo 2. linux_amd64 set/p action=请选择: if %action% == 1 goto build_Windows_amd64 if %action% == 2 goto build_linux_amd64 :build_Windows_amd64 echo 编译Windows版本64位 SET CGO_ENABLED=0 SET GOOS=windows SET GOARCH=amd64 go build -o project-user/target/project-user.exe project-user/main.go go build -o project-api/target/project-api.exe project-api/main.go :build_linux_amd64 echo 编译Linux版本64位 SET CGO_ENABLED=0 SET GOOS=linux SET GOARCH=amd64 go build -o project-user/target/project-user project-user/main.go go build -o project-api/target/project-api project-api/main.go 1 docker image inspect nginx ","date":"2025-04-10T19:04:06+08:00","permalink":"https://yuxiay.github.io/p/docker%E5%88%9D%E6%AD%A5%E8%AE%A4%E8%AF%86/","title":"docker初步认识"},{"content":"Redis 设计一个缓存系统，不得不要考虑的问题就是：缓存穿透、缓存击穿与失效时的雪崩效应。\n前台请求，后台先从缓存中取数据，取到直接返回结果，取不到时从数据库中取，数据库取到更新缓存，并返回结果，数据库也没取到，那直接返回空结果。\n缓存穿透 描述：\n​ 缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求。由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。\n在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。\n如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。\n解决方案：\n接口层增加校验，如用户鉴权校验，id做基础校验，id\u0026lt;=0的直接拦截； 从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击 缓存击穿 描述：\n*缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期）*，这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。\n解决方案：\n1、设置热点数据永远不过期。\n**2、接口限流与熔断，降级。**重要的接口一定要做好限流策略，防止用户恶意刷接口，同时要降级准备，当接口中的某些 服务 不可用时候，进行熔断，失败快速返回机制。\n3、布隆过滤器**。**bloomfilter就类似于一个hash set，用于快速判某个元素是否存在于集合中，其典型的应用场景就是快速判断一个key是否存在于某容器，不存在就直接返回。布隆过滤器的关键就在于hash算法和容器大小，\n4、加互斥锁，互斥锁参考代码如下：\n说明：\n​ 1）缓存中有数据，直接走上述代码13行后就返回结果了\n​ 2）缓存中没有数据，第1个进入的线程，获取锁并从数据库去取数据，没释放锁之前，其他并行进入的线程会等待100ms，再重新去缓存取数据。这样就防止都去数据库重复取数据，重复往缓存中更新数据情况出现。\n​ 3）当然这是简化处理，理论上如果能根据key值加锁就更好了，就是线程A从数据库取key1的数据并不妨碍线程B取key2的数据，上面代码明显做不到这点。\n缓存雪崩 描述：\n缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是， 缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。\n解决方案：\n缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。 如果缓存数据库是分布式部署，将热点数据均匀分布在不同搞得缓存数据库中。 设置热点数据永远不过期。 ","date":"2025-04-06T23:25:36+08:00","permalink":"https://yuxiay.github.io/p/redis%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E5%87%BB%E7%A9%BF%E9%9B%AA%E5%B4%A9/","title":"Redis缓存穿透、击穿、雪崩"},{"content":"go内存分配与逃逸分析 内存管理主要包括俩个动作：分配与释放\n逃逸分析是服务与内存分配的\n而内存的释放由GC负责\n栈 在go语言中，栈的内存是由编译器自动进行分配和释放的，栈区往往存储着函数参数，局部变量和调用函数帧，它们随着函数的创建而分配，随着函数的退出而销毁\ngo应用程序运行时，每个goroutine都维护着一个自己的栈区，这个栈区只能自己使用而不能被其它goroutine使用。栈是调用栈(call stack)的简称。一个栈通常又包含了许多栈帧，它描述的是函数之间的调用关系\n堆 与栈不同的是，堆区的内存一般是由编译器和工程师自己共同进行分配管理的，交给Runtime GC来释放。在堆上分配时，必须找到一块足够大的内存来存放新的变量数据。后续释放时，垃圾回收期扫描堆空间寻找不再被使用的对象\n逃逸分析 相比于把内存分配到堆上，分配到栈中优势更加明显\nGo编译器会尽可能将变量分配到栈上\n但是在函数返回后无法证明变量未被引用，则该变量将被分配到堆上，该变量不随函数栈的回收而回收，以此来避免悬挂指针的问题\n如果变量占用内存大也会放入堆上\nGo是如何确定内存是分配到栈上还是堆上呢？\n答案就是：内存逃逸\n编译器通过逃逸分析技术来选择堆或者栈，逃逸分析的基本思想如下：检查变量的生命周期是否完全可知的，如果通过检查，则在栈上分配，否则就是所谓逃逸，必须在堆上进行分配\n逃逸分析原则 Go语言虽然没有明确说明逃逸分析原则，但有以下几点准则是可以参考的：\n不同于JAVA JVM的运行时逃逸分析，Go的逃逸分析是在编译期完成的：编译期无法确定的参数类型必定放到堆中 如果变量在函数外部存在引用，则必定放在堆中 如果变量占用内存较大时，则优先放到堆中 如果变量在函数外部没有引用，则优先放到栈中 变量大小无法确定时也会发生内存逃逸 ","date":"2025-03-23T23:25:36+08:00","permalink":"https://yuxiay.github.io/p/go%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8/","title":"go内存逃逸"},{"content":"Go语言——垃圾回收 屏障： 1.插入屏障：在A对象引用B对象的时候，B对象被标记为灰色（满足强三色不变式，黑色引用的白色对象会被强制转换为灰色）。只有堆上的对象触发插入屏障，栈上的对象不触发插入屏障。在准备回收白色前，重新遍历扫描一次栈空间。此时加STW暂停保护栈，防止外界干扰。\n不足：结束时需要使用STW来重新扫描栈\n2.删除屏障：被删除的对象，如果自身为灰色或者白色，那么被标记为灰色（满足弱三色不变式）。\n删除屏障的不足：回收精度低，一个对象即使被删除了最后一个指向它的指针也依旧可以活过这一轮，在下一轮GC中被清理掉。\nGo V1.8的三色标记法+混合写屏障机制 具体操作： 1.GC开始将栈上的可达对象全部扫描并标记为黑色（之后不再进行第二次重复扫描，无需STW） 2.GC期间，任何在栈上创建的新对象，均为黑色 3.堆上被删除对象标记为灰色 4.堆上被添加的对象标记为灰色 满足：变形的弱三色不变式（结合了插入、删除写屏障的优点）\n对于堆上的对象，采用三色标记法+写屏障保护\nGC垃圾收集的多个阶段： 1.标记准备阶段；\n启动后台标记任务 暂停程序（STW），所有的处理器在这时会进入安全点（Safe point）； 如果当前垃圾收集循环是强制触发的，我们还需要处理还未被清理的内存管理单元； 将根对象入队 开启写屏障 2.标记阶段；\n恢复用户协程 使用三色标记法开始标记，此时用户协程和标记协程并发执行 3.标记终止阶段；\n暂停用户协程 计算下一次触发GC时需要达到的堆目标 唤醒后台清扫协程 4.清理阶段；\n关闭写屏障 恢复用户协程 异步清理回收\n什么是根对象？ 根对象（root object）是指那些能够从全局可达的地方访问到的对象。垃圾回收器会从根对象开始，通过遍历根对象的引用关系，逐步追踪并标记所有可达的对象。任何未被标记的对象都会被认为是垃圾，最终被回收释放。\n1.全局变量：全局变量可以被程序中的任何位置引用到，因此是根对象。 2.当前正在执行的函数的局部变量：当一个函数正在执行时，其局部变量可以被当前函数中的代码访问到，因此也是根对象。 3.当前正在执行的 goroutine 的栈中的变量：goroutine 是 Go语言并发编程中的轻量级线程，每个 goroutine 都有一块独立的栈空间，其中的变量可以被当前 goroutine 访问到，也是根对象。 4.其他和运行时系统相关的数据结构和变量。\n三色标记法的缺点： 1.暂停时间：在进行垃圾回收时，必须停止程序执行，这会导致应用程序暂停。引入写屏障保护可以减少暂停时间， 但仍然可能导致性能下降。 2.内存开销：三色标记法需要为每个对象维护额外的状态信息，以记录其标记状态。这会增加内存开销，并可能对内 存资源造成负担。 3.频繁的垃圾回收：三色标记法需要频繁地迭代标记和清除对象，如果要回收的垃圾对象很多，可能会导致回收过程 变得非常耗时。 4.碎片化：垃圾回收过程中，如果频繁进行对象的移动和重新分配内存，可能会导致内存碎片化，降低内存的利用 率。\nGC的触发条件 1.主动触发(手动触发)，通过调用 runtime.GC 来触发GC，此调用阻塞式地等待当前GC运行完毕。 2.被动触发，分为两种方式：\n2.1.使用步调（Pacing）算法，其核心思想是控制内存增长的比例,每次内存分配时检查当前内存分配量是否已达到阈值（环境变量GOGC）：默认100%，即当内存扩大一倍时启用GC。 2.2.使用系统监控，当超过两分钟没有产生任何GC时，强制触发 GC。\nGC调优 1.控制内存分配的速度，限制Goroutine的数量，提高赋值器mutator的CPU利用率（降低GC的CPU利用率） 2.少量使用+连接string 3.slice提前分配足够的内存来降低扩容带来的拷贝 4.避免map key对象过多，导致扫描时间增加 5.变量复用，减少对象分配，例如使用sync.Pool来复用需要频繁创建临时对象、使用全局变量等 6.增大GOGC的值，降低GC的运行频率\n","date":"2025-03-23T23:25:36+08:00","permalink":"https://yuxiay.github.io/p/go%E8%AF%AD%E8%A8%80%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/","title":"go语言垃圾回收"},{"content":"前言 我们之前虽然利用zap记录了日志，但是这里面有一些问题，我们假设应用部署在了20台机器上，如果需要查看日志时，我们需要登录到所有的机器上去查看日志，当机器数量在往上增的时候，这样的方式去查看日志，很明显就不合适了\n解决上述问题，有效的思路很明显是讲日志统一收集起来，放在一个统一的地方进行查看。\n当然日志量级非常大，考虑到性能问题，我们引入kafka来做日志采集。\n日志采集有两种方案\n直接将日志发送到kafka 监听之前记录的日志文件，有新增就写入kafka 日志存储方案比较多\nmysql数据库 mongo数据库 ELK（Elasticsearch , Logstash, Kibana）架构 分布式文件存储等 1. kafka Kafka 是一个分布式的流式处理平台，它以高吞吐、可持久化、可水平扩展、支持流数据处理等多种特性而被广泛使用。\nKafka也是我们常说的消息队列中间件。\nKafka的性能非常高，并且非常稳定，即使在大数据量，比如TB级数据量时也能保证稳定的性能，同时Kafka的速度也非常快。\n在不考虑数据零丢失的场景下，Kafka可达到百万级别的吞吐量，数据零丢失的场景下也能达到十万级，所以Kafka的使用非常广。\nKafka的社区活跃度高，开源多年，但Kafka最初就是奔着处理大数据的，所以Kafka是广泛应用在大数据领域，比如流式实时计算，日志采集等方面。\n一些业务场景，可以选择诸如RabBitMQ,RocketMQ等\n1.1 部署 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 kafdrop: container_name: kafdrop image: obsidiandynamics/kafdrop restart: \u0026#34;no\u0026#34; ports: - \u0026#34;9000:9000\u0026#34; environment: KAFKA_BROKERCONNECT: \u0026#34;kafka:29092\u0026#34; JVM_OPTS: \u0026#34;-Xms16M -Xmx48M -Xss180K -XX:-TieredCompilation -XX:+UseStringDeduplication -noverify\u0026#34; depends_on: - \u0026#34;kafka\u0026#34; kafka: container_name: kafka image: obsidiandynamics/kafka restart: \u0026#34;no\u0026#34; ports: - \u0026#34;2181:2181\u0026#34; - \u0026#34;9092:9092\u0026#34; environment: KAFKA_LISTENERS: \u0026#34;INTERNAL://:29092,EXTERNAL://:9092\u0026#34; KAFKA_ADVERTISED_LISTENERS: \u0026#34;INTERNAL://kafka:29092,EXTERNAL://localhost:9092\u0026#34; KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: \u0026#34;INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT\u0026#34; KAFKA_INTER_BROKER_LISTENER_NAME: \u0026#34;INTERNAL\u0026#34; KAFKA_ZOOKEEPER_SESSION_TIMEOUT: \u0026#34;6000\u0026#34; KAFKA_RESTART_ATTEMPTS: \u0026#34;10\u0026#34; KAFKA_RESTART_DELAY: \u0026#34;5\u0026#34; ZOOKEEPER_AUTOPURGE_PURGE_INTERVAL: \u0026#34;0\u0026#34; 1.2 生产者 安装go kafka\n1 go get github.com/segmentio/kafka-go 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // to produce messages topic := \u0026#34;my-topic\u0026#34; partition := 0 conn, err := kafka.DialLeader(context.Background(), \u0026#34;tcp\u0026#34;, \u0026#34;localhost:9092\u0026#34;, topic, partition) if err != nil { log.Fatal(\u0026#34;failed to dial leader:\u0026#34;, err) } conn.SetWriteDeadline(time.Now().Add(10*time.Second)) _, err = conn.WriteMessages( kafka.Message{Value: []byte(\u0026#34;one!\u0026#34;)}, kafka.Message{Value: []byte(\u0026#34;two!\u0026#34;)}, kafka.Message{Value: []byte(\u0026#34;three!\u0026#34;)}, ) if err != nil { log.Fatal(\u0026#34;failed to write messages:\u0026#34;, err) } if err := conn.Close(); err != nil { log.Fatal(\u0026#34;failed to close writer:\u0026#34;, err) } 1.3 消费者 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // to consume messages topic := \u0026#34;my-topic\u0026#34; partition := 0 conn, err := kafka.DialLeader(context.Background(), \u0026#34;tcp\u0026#34;, \u0026#34;localhost:9092\u0026#34;, topic, partition) if err != nil { log.Fatal(\u0026#34;failed to dial leader:\u0026#34;, err) } conn.SetReadDeadline(time.Now().Add(10*time.Second)) batch := conn.ReadBatch(10e3, 1e6) // fetch 10KB min, 1MB max b := make([]byte, 10e3) // 10KB max per message for { n, err := batch.Read(b) if err != nil { break } fmt.Println(string(b[:n])) } if err := batch.Close(); err != nil { log.Fatal(\u0026#34;failed to close batch:\u0026#34;, err) } if err := conn.Close(); err != nil { log.Fatal(\u0026#34;failed to close connection:\u0026#34;, err) } 2. 日志发送 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 package kk import ( \u0026#34;context\u0026#34; \u0026#34;errors\u0026#34; \u0026#34;github.com/segmentio/kafka-go\u0026#34; \u0026#34;go.uber.org/zap\u0026#34; \u0026#34;time\u0026#34; ) type LogData struct { Data string Topic string } type KafkaWriter struct { w *kafka.Writer Data chan LogData } //GetWriter 初始化客户端 func GetWriter(addr string) *KafkaWriter { w := \u0026amp;kafka.Writer{ Addr: kafka.TCP(addr), Balancer: \u0026amp;kafka.LeastBytes{}, } k := \u0026amp;KafkaWriter{w: w, Data: make(chan LogData)} go k.sendMsg() return k } func (kw *KafkaWriter) Send(msg LogData) { kw.Data \u0026lt;- msg } func (kw *KafkaWriter) sendMsg() { for { select { case data := \u0026lt;-kw.Data: msg := kafka.Message{ Topic: data.Topic, Value: []byte(data.Data), } var err error const retries = 3 for i := 0; i \u0026lt; retries; i++ { ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() err = kw.w.WriteMessages(ctx, msg) if err == nil { break } if errors.Is(err, kafka.LeaderNotAvailable) || errors.Is(err, context.DeadlineExceeded) { time.Sleep(time.Millisecond * 250) continue } if err != nil { zap.L().Error(\u0026#34;kafka send log writer msg err\u0026#34;, zap.Error(err)) } } } } } 3. 日志接收 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 package kk import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/segmentio/kafka-go\u0026#34; \u0026#34;go.uber.org/zap\u0026#34; ) type KafkaReader struct { r *kafka.Reader } func (r *KafkaReader) readMsg() { for { m, err := r.r.ReadMessage(context.Background()) if err != nil { zap.L().Error(\u0026#34;kafka receiver read msg err\u0026#34;, zap.Error(err)) continue } fmt.Printf(\u0026#34;message at offset %d: %s = %s\\n\u0026#34;, m.Offset, string(m.Key), string(m.Value)) } } func GetReader(brokers []string, groupId, topic string) *KafkaReader { r := kafka.NewReader(kafka.ReaderConfig{ Brokers: brokers, GroupID: groupId, Topic: topic, MinBytes: 10e3, MaxBytes: 10e6, }) k := \u0026amp;KafkaReader{ r: r, } go k.readMsg() return k } 4. ELK ElasticSearch：负责分布式存储日志数据，给Kibana提供可视化的数据源 LogStash：负责消费Kafka消息队列中的原始数据，并将消费的数据上报到ElasticSearch进行存储 Kibana：负责可视化ElasticSearch中存储的数据，并提供查询、聚合、图表、导出等功能 4.1 部署ES和Kibana 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 es: container_name: es image: elasticsearch:8.6.0 volumes: - ${ES_DIR}/data:/usr/share/elasticsearch/data - ${ES_DIR}/logs:/usr/share/elasticsearch/logs - ${ES_DIR}/plugins:/usr/share/elasticsearch/plugins ports: - 9200:9200 - 9300:9300 environment: - node.name=es - cluster.name=elasticsearch - discovery.type=single-node - bootstrap.memory_lock=true - xpack.security.enabled=false - xpack.security.http.ssl.enabled=false - xpack.security.transport.ssl.enabled=false privileged: true kibana: image: kibana:8.6.0 container_name: kibana depends_on: - es environment: SERVER_NAME: kibana SERVER_HOST: \u0026#34;0.0.0.0\u0026#34; ELASTICSEARCH_HOSTS: http://es:9200 ports: - 5601:5601 ik分词器：\n1 docker-compose exec es elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v8.6.0/elasticsearch-analysis-ik-8.6.0.zip 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 GET _analyze { \u0026#34;analyzer\u0026#34;: \u0026#34;ik_smart\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;我们都是中国人\u0026#34; } GET _analyze { \u0026#34;analyzer\u0026#34;: \u0026#34;ik_max_word\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;我们都是中国人\u0026#34; } GET _analyze { \u0026#34;analyzer\u0026#34;: \u0026#34;standard\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;我们都是中国人\u0026#34; } 4.2 部署logstash logstash.yaml\n1 2 3 4 5 6 7 http.host: \u0026#34;0.0.0.0\u0026#34; #ES地址 xpack.monitoring.elasticsearch.hosts: [\u0026#34;http://es:9200\u0026#34;] xpack.monitoring.enabled: true #ES中的内置账户和密码，在ES中配置 #xpack.monitoring.elasticsearch.username: logstash_system #xpack.monitoring.elasticsearch.password: ***************** logstash.conf\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 input { kafka { topics =\u0026gt; \u0026#34;msproject_log\u0026#34; #kafka的topic bootstrap_servers =\u0026gt; [\u0026#34;kafka:29092\u0026#34;] #服务器地址 codec =\u0026gt; \u0026#34;json\u0026#34; #以Json格式取数据 } } output { elasticsearch { hosts =\u0026gt; [\u0026#34;es:9200\u0026#34;] #ES地址 index =\u0026gt; \u0026#34;msproject_log-%{+YYYY.MM.dd}\u0026#34; #ES index，必须使用小写字母 #user =\u0026gt; \u0026#34;elastic\u0026#34; #这里建议使用 elastic 用户 #password =\u0026gt; \u0026#34;**********\u0026#34; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 logstash: image: logstash:8.6.0 container_name: logstash volumes: - ${LOGSTASH_DIR}/logstash.conf:/usr/share/logstash/pipeline/logstash.conf - ${LOGSTASH_DIR}/logstash.yml:/usr/share/logstash/config/logstash.yml - ${LOGSTASH_DIR}/log/:/home/public/ ports: - \u0026#39;5044:5044\u0026#39; - \u0026#39;50000:50000/tcp\u0026#39; - \u0026#39;50000:50000/udp\u0026#39; - \u0026#39;9600:9600\u0026#39; environment: LS_JAVA_OPTS: -Xms1024m -Xmx1024m TZ: Asia/Shanghai MONITORING_ENABLED: false depends_on: - es 5. 项目记录日志 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package config import \u0026#34;test.com/project-common/kk\u0026#34; var kw *kk.KafkaWriter func InitKafkaWriter() func() { kw = kk.GetWriter(\u0026#34;localhost:9092\u0026#34;) return kw.Close } func SendLog(data []byte) { kw.Send(kk.LogData{ Topic: \u0026#34;msproject_log\u0026#34;, Data: data, }) } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 package kk import ( \u0026#34;encoding/json\u0026#34; \u0026#34;test.com/project-common/tms\u0026#34; \u0026#34;time\u0026#34; ) type FieldMap map[string]any type KafkaLog struct { Type string Action string Time string Msg string Field FieldMap FuncName string } func Error(err error, funcName string, fieldMap FieldMap) []byte { kl := KafkaLog{ Type: \u0026#34;error\u0026#34;, Action: \u0026#34;click\u0026#34;, Time: tms.Format(time.Now()), Msg: err.Error(), Field: fieldMap, FuncName: funcName, } bytes, _ := json.Marshal(kl) return bytes } func Info(msg string, funcName string, fieldMap FieldMap) []byte { kl := KafkaLog{ Type: \u0026#34;info\u0026#34;, Action: \u0026#34;click\u0026#34;, Time: tms.Format(time.Now()), Msg: msg, Field: fieldMap, FuncName: funcName, } bytes, _ := json.Marshal(kl) return bytes } ","date":"2025-03-12T19:09:16+08:00","permalink":"https://yuxiay.github.io/p/kafka-elk%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86/","title":"kafka+ELK日志采集"},{"content":"什么是链路追踪 分布式链路追踪就是将一次分布式请求还原成调用链路，将一次分布式请求的调用情况集中展示，比如各个服务节点上的耗时、请求具体到达哪台机器上、每个服务节点的请求状态等等。\n链路跟踪主要功能：\n故障快速定位：可以通过调用链结合业务日志快速定位错误信息。 链路性能可视化：各个阶段链路耗时、服务依赖关系可以通过可视化界面展现出来。 链路分析：通过分析链路耗时、服务依赖关系可以得到用户的行为路径，汇总分析应用在很多业务场景。 Jaeger Jaeger 是一个分布式追踪系统。Jaeger的灵感来自 Dapper 和 OpenZipkin，是一个由 Uber 创建并捐赠给 云原生计算基金会（CNCF） 的分布式跟踪平台。它可以用于监控基于微服务的分布式系统：\n分布式上下文传递 分布式事务监听 根因分析 服务依赖性分析 性能/延迟优化 Span 一个 Span 表示 Jaeger 的逻辑工作单元，Span 具有操作名称，操作的开始时间，和持续时间。Span 可以嵌套并排序以建立因果关系模型。\nSpan 由以下信息组成：\nAn operation name：操作名称，必有； A start timestamp：开始时间戳，必有； A finish timestamp：结束时间戳，必有； Span Tags.：Key-Value 形式表示请求的标签，可选； Span Logs：Key-Value 形式表示，记录简单的、结构化的日志，必须是字符串类型，可选； SpanContext ：Span上下文，在不同的 span 中传递，建立关系； References：引用的其它 Span； span 之间如果是父子关系，则可以使用 SpanContext 绑定这种关系。父子关系有 ChildOf、FollowsFrom 两种表示，ChildOf 表示 父 Span 在一定程度上依赖子 Span，而 FollowsFrom 表示父 Span 完全不依赖其子Span 的结果。\n例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 { \u0026#34;traceID\u0026#34;: \u0026#34;790e003e22209ca4\u0026#34;, \u0026#34;spanID\u0026#34;: \u0026#34;4b73f8e8e77fe9dc\u0026#34;, \u0026#34;flags\u0026#34;: 1, \u0026#34;operationName\u0026#34;: \u0026#34;print-hello\u0026#34;, \u0026#34;references\u0026#34;: [], \u0026#34;startTime\u0026#34;: 1611318628515966, \u0026#34;duration\u0026#34;: 259, \u0026#34;tags\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;internal.span.format\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;proto\u0026#34; } ], \u0026#34;logs\u0026#34;: [ { \u0026#34;timestamp\u0026#34;: 1611318628516206, \u0026#34;fields\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;event\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;WriteLine\u0026#34; } ] } ] } Trace 一个 Trace 标识通过系统的数据或执行路径，Trace 可被认为是由一组 Span 定义的有向无环图(DAG)。\n在OpenTracing 模型中，有三个主要的对象：\nTracer Span SpanContext Tracer可以创建Spans并了解如何跨流程边界对它们的元数据进行Inject（序列化）和Extract（反序列化）。它具有以下功能：\n开始一个新的 Span Inject一个SpanContext到一个载体 Extract一个SpanContext从载体 在Jaeger中，由起点进程创建一个 Tracer，然后启动进程发起请求，每个动作产生一个 Span，如果有父子关系，Tracer 可以将它们关联起来。当请求完成后， Tracer 将跟踪信息推送到 Jaeger-Collector中。\n组件 Jaeger 可以使用 all-in-one 二进制（其中所有 Jaeger 后端组件都在单个进程中运行）进行部署，也可以作为可扩展的分布式系统进行部署，如下所述。有两个主要的部署选项：\n收集器直接写入存储。\n收集器写入 Kafka 作为中间缓冲。\n2.2.3.1 代理（Agent） Jaeger 代理 是一个网络守护程序，它侦听通过 UDP 发送的 span，然后将其分批发送给收集器（Collector）。它旨在作为基础组件部署到所有主机。该代理为客户端抽象了收集器的路由和发现。\n2.2.3.2 收集器（Collector） Jaeger 收集器从 Jaeger代理或者SDK接收Trace，通过a processing pipeline对Trace做验证，清理，压缩等，并最终存储它们。\nJaeger 的存储是一个可插拔组件，支持 Cassandra，Elasticsearch 和 Kafka等。\n2.2.3.3 查询（Query） 查询是一项从存储中检索Trace并托管 UI 来显示Trace的服务。\n2.2.3.4 Ingester Ingester 是一项从 Kafka topic 读取并写入另一个存储后端（Cassandra，Elasticsearch）的服务。\n2.3 使用 2.3.1 部署Jaeger 简单起见，使用all-in-one的方式部署\n1 2 3 4 5 6 7 8 9 10 11 12 MYSQL_VERSION=8.0.20 MYSQL_DIR=D:/go/project/msproject-data/mysql MYSQL_PORT=3309 REDIS_VERSION=6.2.7 REDIS_PORT=6379 REDIS_DIR=D:/go/project/msproject-data/redis ETCD_VERSION=3.5.6 ETCD_PORT=2379 ETCD_DIR=D:/go/project/msproject-data/etcd NACOS_DIR=D:/go/project/msproject-data/nacos JAEGER_DIR=D:/go/project/msproject-data/jaeger BADGER_EPHEMERAL=false 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 Jaeger: container_name: jaeger image: jaegertracing/all-in-one:1.41 restart: always environment: - COLLECTOR_ZIPKIN_HTTP_PORT=9411 - SPAN_STORAGE_TYPE=badger - BADGER_EPHEMERAL=${BADGER_EPHEMERAL} - BADGER_DIRECTORY_VALUE=/badger/data - BADGER_DIRECTORY_KEY=/badger/key privileged: true volumes: - ${JAEGER_DIR}:/badger ports: - 5775:5775/udp - 6831:6831/udp - 6832:6832/udp - 5778:5778 - 16686:16686 - 14268:14268 - 14269:14269 - 9411:9411 访问：http://localhost:16686/search\n2.3.2 gin中间件 1 2 3 4 5 6 go get go.opentelemetry.io/otel go get go.opentelemetry.io/otel/sdk go get go.opentelemetry.io/contrib/instrumentation/github.com/gin-gonic/gin/otelgin go get go.opentelemetry.io/contrib/instrumentation/google.golang.org/grpc/otelgrpc go get -u go.opentelemetry.io/otel/exporters/jaeger go get github.com/grpc-ecosystem/go-grpc-middleware 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 package tracing import ( \u0026#34;go.opentelemetry.io/otel/exporters/jaeger\u0026#34; \u0026#34;go.opentelemetry.io/otel/sdk/resource\u0026#34; sdktrace \u0026#34;go.opentelemetry.io/otel/sdk/trace\u0026#34; semconv \u0026#34;go.opentelemetry.io/otel/semconv/v1.4.0\u0026#34; ) func JaegerTraceProvider() (*sdktrace.TracerProvider, error) { exp, err := jaeger.New(jaeger.WithCollectorEndpoint(jaeger.WithEndpoint(\u0026#34;http://localhost:14268/api/traces\u0026#34;))) if err != nil { return nil, err } tp := sdktrace.NewTracerProvider( sdktrace.WithBatcher(exp), sdktrace.WithResource(resource.NewWithAttributes( semconv.SchemaURL, semconv.ServiceNameKey.String(\u0026#34;project-project\u0026#34;), semconv.DeploymentEnvironmentKey.String(\u0026#34;dev\u0026#34;), )), ) return tp, nil } 1 2 3 4 5 6 7 tp, tpErr := tracing.JaegerTraceProvider() if tpErr != nil { log.Fatal(tpErr) } otel.SetTracerProvider(tp) otel.SetTextMapPropagator(propagation.NewCompositeTextMapPropagator(propagation.TraceContext{}, propagation.Baggage{})) gin中间件：\n1 r.Use(otelgin.Middleware(\u0026#34;project-api\u0026#34;)) grpc：\n1 2 3 4 5 conn, err := grpc.Dial( \u0026#34;etcd:///user\u0026#34;, grpc.WithTransportCredentials(insecure.NewCredentials()), grpc.WithUnaryInterceptor(otelgrpc.UnaryClientInterceptor()), ) 1 2 3 4 5 6 s := grpc.NewServer( grpc.UnaryInterceptor(grpc_middleware.ChainUnaryServer( otelgrpc.UnaryServerInterceptor(), //interceptor.New().CacheInterceptor(), )), ) ","date":"2025-03-02T16:09:16+08:00","permalink":"https://yuxiay.github.io/p/jaeger%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA/","title":"Jaeger链路追踪"},{"content":"nacos分布式配置中心 通过nacos进行远程配置，可以实现配置更改之后第一时间进行更新操作，本地需要对nacos进行连接\n通过viper进行映射\n1 2 3 4 5 6 7 nacos: namespace: de94f0c7-5ad9-4ecc-bcf1-2f9d2732e766 group: dev ipAddr: 127.0.0.1 port: 8848 scheme: http contextPath: \u0026#34;/nacos\u0026#34; 1 2 3 4 5 6 7 8 type NacosConfig struct { Namespace string Group string IpAddr string Port int ContextPath string Scheme string } 进行nacos 连接\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 type NacosClient struct { confClient config_client.IConfigClient group string } func InitNacosClient() *NacosClient { bootConf := InitBootstrap() clientConfig := constant.ClientConfig{ NamespaceId: bootConf.NacosConfig.Namespace, //we can create multiple clients with different namespaceId to support multiple namespace.When namespace is public, fill in the blank string here. TimeoutMs: 5000, NotLoadCacheAtStart: true, LogDir: \u0026#34;/tmp/nacos/log\u0026#34;, CacheDir: \u0026#34;/tmp/nacos/cache\u0026#34;, LogLevel: \u0026#34;debug\u0026#34;, } serverConfigs := []constant.ServerConfig{ { IpAddr: bootConf.NacosConfig.IpAddr, ContextPath: bootConf.NacosConfig.ContextPath, Port: uint64(bootConf.NacosConfig.Port), Scheme: bootConf.NacosConfig.Scheme, }, } configClient, err := clients.NewConfigClient( vo.NacosClientParam{ ClientConfig: \u0026amp;clientConfig, ServerConfigs: serverConfigs, }, ) if err != nil { log.Fatalln(err) } nc := \u0026amp;NacosClient{ confClient: configClient, group: bootConf.NacosConfig.Group, } return nc } nacos可以通过监听，来实现当配置文件更改时，可以重新加载配置文件，但要注意此时数据库已经进行连接初始化，要重新进行连接数据库\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 err2 = nacosClient.confClient.ListenConfig(vo.ConfigParam{ DataId: \u0026#34;config.yaml\u0026#34;, Group: nacosClient.group, OnChange: func(namespace, group, dataId, data string) { // log.Printf(\u0026#34;load nacos config changed %s \\n\u0026#34;, data) err := conf.viper.ReadConfig(bytes.NewBuffer([]byte(data))) if err != nil { log.Printf(\u0026#34;load nacos config changed err : %s \\n\u0026#34;, err.Error()) } //所有的配置应该重新读取 conf.ReLoadAllConfig() }, }) ","date":"2025-03-01T16:09:16+08:00","permalink":"https://yuxiay.github.io/p/nacos%E5%88%86%E5%B8%83%E5%BC%8F%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/","title":"Nacos分布式配置中心"},{"content":"etcd原理与应用 etcd 是一款分布式存储中间件，使用Go语言编写并通过Raft一致性算法处理和确保分布式一致性，解决了分布式系统中数据一致性的问题\ngo 语言etcd基本操作 1 2 3 4 // etcd连接 cli, err := clientv3.New(clientv3.Config{ End }) 服务注册和服务发现的具体实现 基本逻辑：服务注册者向etcd注册服务，客户端查询监听etcd，从而客户端访问服务\n服务端：\n启动服务 向etcd注册服务 声明租约并续约 客户端：\n第一次获取服务信息 创建监听，被动接受服务信息 更新本地服务信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 package main import ( \u0026#34;context\u0026#34; \u0026#34;log\u0026#34; \u0026#34;time\u0026#34; \u0026#34;go.etcd.io/etcd/clientv3\u0026#34; ) //ServiceRegister 创建租约注册服务 type ServiceRegister struct { cli *clientv3.Client //etcd client leaseID clientv3.LeaseID //租约ID //租约keepalieve相应chan keepAliveChan \u0026lt;-chan *clientv3.LeaseKeepAliveResponse key string //key val string //value } //NewServiceRegister 新建注册服务 func NewServiceRegister(endpoints []string, key, val string, lease int64) (*ServiceRegister, error) { cli, err := clientv3.New(clientv3.Config{ Endpoints: endpoints, DialTimeout: 5 * time.Second, }) if err != nil { log.Fatal(err) } ser := \u0026amp;ServiceRegister{ cli: cli, key: key, val: val, } //申请租约设置时间keepalive if err := ser.putKeyWithLease(lease); err != nil { return nil, err } return ser, nil } //设置租约 func (s *ServiceRegister) putKeyWithLease(lease int64) error { //设置租约时间 resp, err := s.cli.Grant(context.Background(), lease) if err != nil { return err } //注册服务并绑定租约 _, err = s.cli.Put(context.Background(), s.key, s.val, clientv3.WithLease(resp.ID)) if err != nil { return err } //设置续租 定期发送需求请求 leaseRespChan, err := s.cli.KeepAlive(context.Background(), resp.ID) if err != nil { return err } s.leaseID = resp.ID log.Println(s.leaseID) s.keepAliveChan = leaseRespChan log.Printf(\u0026#34;Put key:%s val:%s success!\u0026#34;, s.key, s.val) return nil } //ListenLeaseRespChan 监听 续租情况 func (s *ServiceRegister) ListenLeaseRespChan() { for leaseKeepResp := range s.keepAliveChan { log.Println(\u0026#34;续约成功\u0026#34;, leaseKeepResp) } log.Println(\u0026#34;关闭续租\u0026#34;) } // Close 注销服务 func (s *ServiceRegister) Close() error { //撤销租约 if _, err := s.cli.Revoke(context.Background(), s.leaseID); err != nil { return err } log.Println(\u0026#34;撤销租约\u0026#34;) return s.cli.Close() } func main() { var endpoints = []string{\u0026#34;localhost:2379\u0026#34;} ser, err := NewServiceRegister(endpoints, \u0026#34;/web/node1\u0026#34;, \u0026#34;localhost:8000\u0026#34;, 5) if err != nil { log.Fatalln(err) } //监听续租相应chan go ser.ListenLeaseRespChan() select { // case \u0026lt;-time.After(20 * time.Second): // ser.Close() } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 package main import ( \u0026#34;context\u0026#34; \u0026#34;log\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/coreos/etcd/mvcc/mvccpb\u0026#34; \u0026#34;go.etcd.io/etcd/clientv3\u0026#34; ) //ServiceDiscovery 服务发现 type ServiceDiscovery struct { cli *clientv3.Client //etcd client serverList map[string]string //服务列表 lock sync.Mutex } //NewServiceDiscovery 新建发现服务 func NewServiceDiscovery(endpoints []string) *ServiceDiscovery { cli, err := clientv3.New(clientv3.Config{ Endpoints: endpoints, DialTimeout: 5 * time.Second, }) if err != nil { log.Fatal(err) } return \u0026amp;ServiceDiscovery{ cli: cli, serverList: make(map[string]string), } } //WatchService 初始化服务列表和监视 func (s *ServiceDiscovery) WatchService(prefix string) error { //根据前缀获取现有的key resp, err := s.cli.Get(context.Background(), prefix, clientv3.WithPrefix()) if err != nil { return err } for _, ev := range resp.Kvs { s.SetServiceList(string(ev.Key), string(ev.Value)) } //监视前缀，修改变更的server go s.watcher(prefix) return nil } //watcher 监听前缀 func (s *ServiceDiscovery) watcher(prefix string) { rch := s.cli.Watch(context.Background(), prefix, clientv3.WithPrefix()) log.Printf(\u0026#34;watching prefix:%s now...\u0026#34;, prefix) for wresp := range rch { for _, ev := range wresp.Events { switch ev.Type { case mvccpb.PUT: //修改或者新增 s.SetServiceList(string(ev.Kv.Key), string(ev.Kv.Value)) case mvccpb.DELETE: //删除 s.DelServiceList(string(ev.Kv.Key)) } } } } //SetServiceList 新增服务地址 func (s *ServiceDiscovery) SetServiceList(key, val string) { s.lock.Lock() defer s.lock.Unlock() s.serverList[key] = string(val) log.Println(\u0026#34;put key :\u0026#34;, key, \u0026#34;val:\u0026#34;, val) } //DelServiceList 删除服务地址 func (s *ServiceDiscovery) DelServiceList(key string) { s.lock.Lock() defer s.lock.Unlock() delete(s.serverList, key) log.Println(\u0026#34;del key:\u0026#34;, key) } //GetServices 获取服务地址 func (s *ServiceDiscovery) GetServices() []string { s.lock.Lock() defer s.lock.Unlock() addrs := make([]string, 0) for _, v := range s.serverList { addrs = append(addrs, v) } return addrs } //Close 关闭服务 func (s *ServiceDiscovery) Close() error { return s.cli.Close() } func main() { var endpoints = []string{\u0026#34;localhost:2379\u0026#34;} ser := NewServiceDiscovery(endpoints) defer ser.Close() ser.WatchService(\u0026#34;/web/\u0026#34;) ser.WatchService(\u0026#34;/gRPC/\u0026#34;) for { select { case \u0026lt;-time.Tick(10 * time.Second): log.Println(ser.GetServices()) } } } ","date":"2025-02-13T21:32:56+08:00","permalink":"https://yuxiay.github.io/p/etcd%E5%8E%9F%E7%90%86%E4%B8%8E%E5%BA%94%E7%94%A8/","title":"etcd原理与应用"},{"content":"Minio 在项目中，存储文件有三种选择：\n存本地 一般是不选择 （带宽风险 服务器带宽是有限的，集群部署 图片是存在不同的服务器） 存云存储 比如阿里云存储oss 七牛云存储 收费的，针对企业用户 存入分布式存储系统（自己搭建） 内网搭建 也能支持 对我们售卖是有帮助的 在一般情况下，使用云存储是最佳选择，但有些时候，尤其是To B的业务，使用自己搭建的分布式存储服务更加适合。\nMinIO 是一款高性能、分布式的对象存储系统. 它是一款软件产品, 可以100%的运行在标准硬件。即X86等低成本机器也能够很好的运行MinIO。\n它基于Apache License 开源协议，兼容Amazon S3云存储接口。适合存储非结构化数据，如图片，音频，视频，日志等。对象文件最大可以达到5TB。\nMinIO是CNCF成员，在云原生存储部分和ceph等一起作为目前的解决方案之一。\nMinIO用作云原生应用程序的主要存储，与传统对象存储相比，云原生应用程序需要更高的吞吐量和更低的延迟。而这些都是MinIO能够达成的性能指标。\ndocker部署 1 2 3 4 5 6 7 8 9 10 11 minio: container_name: minio image: bitnami/minio:2023 ports: - \u0026#39;9009:9000\u0026#39; - \u0026#39;9001:9001\u0026#39; environment: - MINIO_ROOT_USER=admin - MINIO_ROOT_PASSWORD=admin123456 volumes: - \u0026#39;${MINIO_DIR}/data:/data\u0026#39; Minio进行连接和文件上传 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 type MinioClient struct { c *minio.Client } func New(endpoint, accessKey, secretKey string, useSSL bool) (*MinioClient, error) { // Initialize minio client object. minioClient, err := minio.New(endpoint, \u0026amp;minio.Options{ Creds: credentials.NewStaticV4(accessKey, secretKey, \u0026#34;\u0026#34;), Secure: useSSL, }) return \u0026amp;MinioClient{c: minioClient}, err } func (c *MinioClient) Upload( ctx context.Context, bucket string, fileName string, contentType string, data []byte) (minio.UploadInfo, error) { object, err := c.c.PutObject( ctx, bucket, fileName, bytes.NewBuffer(data), int64(len(data)), minio.PutObjectOptions{ContentType: contentType}, ) return object, err } func (c *MinioClient) Compose( ctx context.Context, bucket string, fileName string, contentType string, totalChunk int) error { dstOpts := minio.CopyDestOptions{ Bucket: bucket, Object: fileName, } var srcs []minio.CopySrcOptions for i := 1; i \u0026lt;= totalChunk; i++ { formatInt := strconv.FormatInt(int64(i), 10) src := minio.CopySrcOptions{ Bucket: bucket, Object: fileName + \u0026#34;_\u0026#34; + formatInt, } srcs = append(srcs, src) } _, err := c.c.ComposeObject(context.Background(), dstOpts, srcs...) return err } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 func (t *HandlerTask) uploadFiles(c *gin.Context) { result := \u0026amp;common.Result{} req := model.UploadFileReq{} c.ShouldBind(\u0026amp;req) multipartForm, err := c.MultipartForm() if err != nil { zap.L().Error(\u0026#34;c.MultipartForm() err\u0026#34;, zap.Error(err)) return } file := multipartForm.File key := \u0026#34;\u0026#34; minioClient, err := mio.New( \u0026#34;localhost:9009\u0026#34;, \u0026#34;0RnUy2AUBZrpsI3U\u0026#34;, \u0026#34;9lHE5HpEUwHni1vxaFnf9BosILz79nd3\u0026#34;, false) if err != nil { c.JSON(http.StatusOK, result.Fail(-999, err.Error())) return } if req.TotalChunks == 1 { header := file[\u0026#34;file\u0026#34;][0] open, err := header.Open() defer open.Close() buf := make([]byte, req.TotalSize) open.Read(buf) info, err := minioClient.Upload( context.Background(), \u0026#34;test\u0026#34;, req.Filename, header.Header.Get(\u0026#34;Content-Type\u0026#34;), buf, ) if err != nil { c.JSON(http.StatusOK, result.Fail(-999, err.Error())) } key = info.Bucket + \u0026#34;/\u0026#34; + req.Filename } if req.TotalChunks \u0026gt; 1 { buf := make([]byte, req.CurrentChunkSize) //分片上传 合起来即可 header := file[\u0026#34;file\u0026#34;][0] open, _ := header.Open() defer open.Close() open.Read(buf) formatInt := strconv.FormatInt(int64(req.ChunkNumber), 10) info, err := minioClient.Upload( context.Background(), \u0026#34;test\u0026#34;, req.Filename+\u0026#34;_\u0026#34;+formatInt, header.Header.Get(\u0026#34;Content-Type\u0026#34;), buf, ) if err != nil { c.JSON(http.StatusOK, result.Fail(-999, err.Error())) } key = info.Bucket + \u0026#34;/\u0026#34; + req.Filename if req.TotalChunks == req.ChunkNumber { err := minioClient.Compose( context.Background(), \u0026#34;test\u0026#34;, req.Filename, header.Header.Get(\u0026#34;Content-Type\u0026#34;), req.TotalChunks, ) if err != nil { c.JSON(http.StatusOK, result.Fail(-999, err.Error())) } } } //调用服务 存入file表 ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second) defer cancel() fileUrl := \u0026#34;http://localhost:9009/\u0026#34; + key msg := \u0026amp;task.TaskFileReqMessage{ TaskCode: req.TaskCode, ProjectCode: req.ProjectCode, OrganizationCode: c.GetString(\u0026#34;organizationCode\u0026#34;), PathName: key, FileName: req.Filename, Size: int64(req.TotalSize), Extension: path.Ext(key), FileUrl: fileUrl, FileType: file[\u0026#34;file\u0026#34;][0].Header.Get(\u0026#34;Content-Type\u0026#34;), MemberId: c.GetInt64(\u0026#34;memberId\u0026#34;), } if req.TotalChunks == req.ChunkNumber { _, err = TaskServiceClient.SaveTaskFile(ctx, msg) if err != nil { code, msg := errs.ParseGrpcError(err) c.JSON(http.StatusOK, result.Fail(code, msg)) } } c.JSON(http.StatusOK, result.Success(gin.H{ \u0026#34;file\u0026#34;: key, \u0026#34;hash\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;key\u0026#34;: key, \u0026#34;url\u0026#34;: \u0026#34;http://localhost:9009/\u0026#34; + key, \u0026#34;projectName\u0026#34;: req.ProjectName, })) return } ","date":"2025-02-12T16:09:16+08:00","permalink":"https://yuxiay.github.io/p/minio%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/","title":"Minio文件存储"},{"content":"Mysql主从复制2 MySQL主从复制是一个异步的复制过程，底层是基于Mysql数据库自带的 binlog 功能。就是一台或多台MySQL数据库 从另一台MySQL数据库进行日志的复制，然后再解析日志并应用到自身，最终实现 从库 的数据和 主库 的数据保持一致。 binlog记录了所有的 DDL（数据定义语言）语句和 DML（数据操纵语言）语句，但是不包括数据查询语句。此日志对于灾难时的数据恢复起着极其重要的作用。 mysql默认未开启binlog，所以部署mysql的时候，配置文件需要开启binlog 主库会生成一个 log dump 线程,用来给从库 I/O 线程传 Binlog 数据。\n从库的 I/O 线程会去请求主库的 Binlog，并将得到的 Binlog 写到本地的 relay log (中继日志)文件中。\nSQL 线程,会读取 relay log 文件中的日志，并解析成 SQL 语句逐一执行。\n复制过程 MySQL主从复制的两种情况：同步复制和异步复制，实际复制架构中大部分为异步复制。\nMySQL 主从复制默认是 异步的模式。MySQL增删改操作会全部记录在 Binlog 中，当 slave 节点连接 master 时，会主动从 master 处获取最新的 Binlog 文件。并把 Binlog 存储到本地的 relay log 中，然后去执行 relay log 的更新内容。\n从服务器 I/O 线程将主服务器的 Binlog 日志读取过来，解析到各类 Events 之后记录到从服务器本地文件，这个文件就被称为 relay log。然后 SQL 线程会读取 relay log 日志的内容并应用到从服务器，从而使从服务器和主服务器的数据保持一致。relay log充当缓冲区，这样 master 就不必等待 slave 执行完成才发送下一个事件。\n主流模型 主从复制的模式 异步模式\n这种模式下，主节点不会主动推送bin-log到从节点，主库在执行完客户端提交的事务后会立即将结果返给给客户端，并不关心从库是否已经接收并处理，这样就会有一个问题，主节点如果崩溃掉了，此时主节点上已经提交的事务可能并没有传到从节点上，如果此时，强行将从提升为主，可能导致新主节点上的数据不完整。\n半同步模式\n介于异步复制和全同步复制之间，主库在执行完客户端提交的事务后不是立刻返回给客户端，而是等待至少一个从库接收到并写到relay-log中才返回成功信息给客户端（只能保证主库的bin-log至少传输到了一个从节点上，但并不能保证从节点将此事务执行更新到db中），否则需要等待直到超时时间然后切换成异步模式再提交。相对于异步复制，半同步复制提高了数据的安全性，一定程度的保证了数据能成功备份到从库，同时它也造成了一定程度的延迟，但是比全同步模式延迟要低，这个延迟最少是一个TCP/IP往返的时间。所以，半同步复制最好在低延时的网络中使用。\n全同步模式\n指当主库执行完一个事务，然后所有的从库都复制了该事务并成功执行完才返回成功信息给客户端。因为需要等待所有从库执行完该事务才能返回成功信息，所以全同步复制的性能必然会收到严重的影响。\nSlave 同步延迟\n因为 Slave 端是通过 I/O thread 单线程来实现数据解析入库；而 Master 端写 Binlog 由于是顺序写效率很高，当主库的 TPS 很高的时候，必然 Master 端的写效率要高过 Slave 端的读效率，这时候就有同步延迟的问题。\n实现 这里我们不实际部署主从模式\n配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 db: separation: true master: name: master username: root password: root host: 127.0.0.1 port: 3309 db: msproject slave: - username: root password: root host: 127.0.0.1 port: 3309 db: msproject_slave1 name: slave1 - username: root password: root host: 127.0.0.1 port: 3309 db: msproject_slave1 name: slave2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 func (c *Config) InitDbConfig() { mc := DbConfig{} mc.Separation = c.viper.GetBool(\u0026#34;db.separation\u0026#34;) var slaves []MysqlConfig err := c.viper.UnmarshalKey(\u0026#34;db.slave\u0026#34;, \u0026amp;slaves) if err != nil { panic(err) } master := MysqlConfig{ Username: c.viper.GetString(\u0026#34;db.master.username\u0026#34;), Password: c.viper.GetString(\u0026#34;db.master.password\u0026#34;), Host: c.viper.GetString(\u0026#34;db.master.host\u0026#34;), Port: c.viper.GetInt(\u0026#34;db.master.port\u0026#34;), Db: c.viper.GetString(\u0026#34;db.master.db\u0026#34;), } mc.Master = master mc.Slave = slaves c.DbConfig = mc } 1 go get gorm.io/plugin/dbresolver 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 package gorms import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;gorm.io/driver/mysql\u0026#34; \u0026#34;gorm.io/gorm\u0026#34; \u0026#34;gorm.io/gorm/logger\u0026#34; \u0026#34;gorm.io/plugin/dbresolver\u0026#34; \u0026#34;test.com/project-project/config\u0026#34; ) var _db *gorm.DB func init() { if config.C.DbConfig.Separation { //读写分离配置 username := config.C.DbConfig.Master.Username //账号 password := config.C.DbConfig.Master.Password //密码 host := config.C.DbConfig.Master.Host //数据库地址，可以是Ip或者域名 port := config.C.DbConfig.Master.Port //数据库端口 Dbname := config.C.DbConfig.Master.Db //数据库名 dsn := fmt.Sprintf(\u0026#34;%s:%s@tcp(%s:%d)/%s?charset=utf8\u0026amp;parseTime=True\u0026amp;loc=Local\u0026#34;, username, password, host, port, Dbname) var err error _db, err = gorm.Open(mysql.Open(dsn), \u0026amp;gorm.Config{ Logger: logger.Default.LogMode(logger.Info), }) if err != nil { panic(\u0026#34;连接数据库失败, error=\u0026#34; + err.Error()) } replicas := []gorm.Dialector{} for _, v := range config.C.DbConfig.Slave { username := v.Username //账号 password := v.Password //密码 host := v.Host //数据库地址，可以是Ip或者域名 port := v.Port //数据库端口 Dbname := v.Db //数据库名 dsn := fmt.Sprintf(\u0026#34;%s:%s@tcp(%s:%d)/%s?charset=utf8\u0026amp;parseTime=True\u0026amp;loc=Local\u0026#34;, username, password, host, port, Dbname) cfg := mysql.Config{ DSN: dsn, } replicas = append(replicas, mysql.New(cfg)) } _db.Use(dbresolver.Register(dbresolver.Config{ Sources: []gorm.Dialector{mysql.New(mysql.Config{ DSN: dsn, })}, Replicas: replicas, Policy: dbresolver.RandomPolicy{}, }). SetMaxIdleConns(10). SetMaxOpenConns(200)) } else { //配置MySQL连接参数 username := config.C.MysqlConfig.Username //账号 password := config.C.MysqlConfig.Password //密码 host := config.C.MysqlConfig.Host //数据库地址，可以是Ip或者域名 port := config.C.MysqlConfig.Port //数据库端口 Dbname := config.C.MysqlConfig.Db //数据库名 dsn := fmt.Sprintf(\u0026#34;%s:%s@tcp(%s:%d)/%s?charset=utf8\u0026amp;parseTime=True\u0026amp;loc=Local\u0026#34;, username, password, host, port, Dbname) var err error _db, err = gorm.Open(mysql.Open(dsn), \u0026amp;gorm.Config{ Logger: logger.Default.LogMode(logger.Info), }) if err != nil { panic(\u0026#34;连接数据库失败, error=\u0026#34; + err.Error()) } } } func GetDB() *gorm.DB { return _db } type GormConn struct { db *gorm.DB tx *gorm.DB } func (g *GormConn) Begin() { g.tx = GetDB().Begin() } func New() *GormConn { return \u0026amp;GormConn{db: GetDB()} } func NewTran() *GormConn { return \u0026amp;GormConn{db: GetDB(), tx: GetDB()} } func (g *GormConn) Session(ctx context.Context) *gorm.DB { return g.db.Session(\u0026amp;gorm.Session{Context: ctx}) } func (g *GormConn) Rollback() { g.tx.Rollback() } func (g *GormConn) Commit() { g.tx.Commit() } func (g *GormConn) Tx(ctx context.Context) *gorm.DB { return g.tx.WithContext(ctx) } ","date":"2025-01-02T16:09:16+08:00","permalink":"https://yuxiay.github.io/p/mysql%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/","title":"MySQL读写分离主从复制"},{"content":"从0开始理解rpc rpc核心概念理解 什么是RPC\n​\tRPC远程过程调用，简单理解是一个节点请求另一个节点提供的服务\n​\t对应rpc的是本地过程调用，函数调用是最常见的本地过程调用\n函数调用过程\n将数据压入函数的栈中 函数，从栈中取出数据并赋值 执行函数操作，并将结果赋值给局部变量并压入栈中 回到主函数，将栈中的值取出来赋值给全局变量 远程过程面临问题\nCall的id映射 序列化和反序列化 网络传输 rpc开发的四大要素\n客户端 客户端存根 服务端 服务端存根 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 package main import \u0026#34;fmt\u0026#34; /* 我们原本的电商系统，有一个逻辑，这个逻辑是扣减库存 但是库存服务是一个独立的系统，reduce，那如何调用一定会牵扯到网络，做成一个web服务 1. 这个函数的调用参数是如何传递的--JSON 现在网络调用有俩个端 - 客户端、应该干嘛？将数据传输到GIN gin-服务端，服务端负责解析数据 */ type Company struct { Name string Address string } type Employee struct { Name string Company *Company } type PrintResult struct { Info string Err error } func Add(a, b int) int { return a + b } func RpcPrintln(employee Employee) { // rpc中的第二个点 传输协议，数据编码协议 // http1.x http2.0协议 // http协议底层tcp http现在主流是1.x 这种协议有性能问题 一次性 一旦结果返回连接就断开 // 直接基于tcp/udp 协议去封装一层协议MyHttp，没有通用性， 更好的选择http2.0 既有http的特性，也有长连接的特性 /* 客户端 1. 建立连接 tcp/http连接 2. 将employee对象序列化成json字符串--序列化 3. 发送json字符串 - 调用成功后实际上你接受到的是一个二进制数据 4. 等待服务器发送结果 5. 将服务器返回的数据解析成PrintResult对象 - 反序列化 服务端 1. 监听网络端口 2. 读取数据 - 二进制json数据 3. 对数据进行反序列化Employee对象 4. 开始处理业务逻辑 5. 将处理结果PrintResult序列化成json二进制数据 - 序列化 6. 将数据返回 */ } func main() { //fmt.Println(Add(1, 2)) // 将这个打印的工作放在另一台服务器上 // 没办法直接将本地的内存对象struct传入 // 可行的方式是将struct序列化成json二进制对象 fmt.Println(Employee{ Name: \u0026#34;yuxiay\u0026#34;, Company: \u0026amp;Company{ Name: \u0026#34;天理\u0026#34;, Address: \u0026#34;天津\u0026#34;, }, }) // 远程的服务器需要将二进制对象反解成struct对象 } 简单的客户端\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 package main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/kirinlabs/HttpRequest\u0026#34; ) // rpc远程过程调用，如何做到像本地调用 type ResponseData struct { Data int `json:\u0026#34;data\u0026#34;` } func Add(a, b int) int { // 传输协议: http req := HttpRequest.NewRequest() res, _ := req.Get(fmt.Sprintf(\u0026#34;http://127.0.0.1:8080/%s?a=%d\u0026amp;b=%d\u0026#34;, \u0026#34;add\u0026#34;, a, b)) body, _ := res.Body() //fmt.Println(string(body)) rspData := ResponseData{} _ = json.Unmarshal(body, \u0026amp;rspData) return rspData.Data } func main() { fmt.Println(Add(1, 2)) } 简单的服务端\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 package main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;strconv\u0026#34; ) func main() { // http://127.0.0.1:8000/add?a=1\u0026amp;b=2 // 返回的格式化： json{“data”：3} // 1. callID的问题： r.URL.Path 2. 数据传输协议 url的参数传递协议 3. 网络传输协议 http http.HandleFunc(\u0026#34;/add\u0026#34;, func(w http.ResponseWriter, r *http.Request) { _ = r.ParseForm() // 解析参数 fmt.Println(\u0026#34;path\u0026#34;, r.URL.Path) a, _ := strconv.Atoi(r.Form[\u0026#34;a\u0026#34;][0]) b, _ := strconv.Atoi(r.Form[\u0026#34;b\u0026#34;][0]) w.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) jData, _ := json.Marshal(map[string]int{ \u0026#34;data\u0026#34;: a + b, }) _, _ = w.Write(jData) }) _ = http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) } go内置rpc快速开发 什么是grpc和protobuf gRPC 是一个高性能、开源和通用的 RPC 框架，面向移动和 HTTP/2 设计。目前提供 C、Java 和 Go 语言版本，分 别是：grpc, grpc-java, grpc-go. 其中 C 版本支持 C, C++, Node.js, Python, Ruby, Objective-C, PHP 和 C# 支持. grpc 项目地址优质IT资源微信x923713\nprotobuf java 中的 dubbo dubbo/rmi/hessian messagepack 如果你懂了协议完全有能力自己去实现一个协议 习惯用 Json、XML 数据存储格式的你们，相信大多都没听过 Protocol Buffer Protocol Buffer 其实 是 Google 出品的一种轻量 \u0026amp; 高效的结构化数据存储格式，性能比 Json、XML 真 的强！太！多！ protobuf 经历了 protobuf2 和 protobuf3，pb3 比 pb2 简化了很多，目前主流的版本是 pb3优质IT资源微信x923713\ngo语言grpc快速体验 proto(简单模式)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 syntax = \u0026#34;proto3\u0026#34;; option go_package = \u0026#34;.; proto\u0026#34;; service Greeter{ rpc SayHello(HelloRequest) returns (HelloReply); } message HelloRequest{ string name = 1; } message HelloReply{ string message = 1; } // go语言生成俩个文件a 通过这个生成文件\n1 protoc -I . user.proto --go_out=. --go-grpc_out=. server服务端\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 package main import ( \u0026#34;context\u0026#34; \u0026#34;go_study_demo/ch2/grpc_test/proto\u0026#34; \u0026#34;net\u0026#34; \u0026#34;google.golang.org/grpc\u0026#34; ) type Server struct { proto.UnimplementedGreeterServer // 添加这行 } func (s *Server) SayHello(ctx context.Context, request *proto.HelloRequest) (*proto.HelloReply, error) { return \u0026amp;proto.HelloReply{ Message: \u0026#34;hello\u0026#34; + request.Name, }, nil } func main() { // 1.实例化一个server g := grpc.NewServer() // 2.注册处理逻辑handler proto.RegisterGreeterServer(g, \u0026amp;Server{}) lis, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:8888\u0026#34;) if err != nil { panic(\u0026#34;failed to listen\u0026#34; + err.Error()) } // 3.启动服务 _ = g.Serve(lis) } client客户端\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;go_study_demo/ch2/grpc_test/proto\u0026#34; \u0026#34;google.golang.org/grpc/credentials/insecure\u0026#34; \u0026#34;google.golang.org/grpc\u0026#34; ) func main() { conn, err := grpc.NewClient(\u0026#34;127.0.0.1:8888\u0026#34;, grpc.WithTransportCredentials(insecure.NewCredentials())) if err != nil { panic(\u0026#34;failed\u0026#34;) } defer conn.Close() c := proto.NewGreeterClient(conn) r, err := c.SayHello(context.Background(), \u0026amp;proto.HelloRequest{ Name: \u0026#34;grpc\u0026#34;, }) if err != nil { panic(err) } fmt.Println(r.Message) } grpc流模式调用 grpc四种数据流\n简单模式\n​\t即客户端发起一次请求，服务端响应一个数据\n服务端数据流模式\n​\t客户端发起一次请求，服务端返回一段连续的数据流\n客户端数据流模式\n​\t客户端源源不断的向服务端发送数据流，而在发送结束后，由服务端返回一个响应\n双向流模式\n​\t客户端和服务端都可以向对方发送数据流，这个时候双方的数据可以同时互相发送，可以实现实时交互，典型例子是聊天\nproto\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 syntax = \u0026#34;proto3\u0026#34;; option go_package = \u0026#34;.;proto\u0026#34;; service Greeter{ rpc GetStream(StreamReqData) returns (stream StreamResData); // 服务端流模式 rpc PutStream(stream StreamReqData) returns (StreamResData); // 客户端流模式 rpc AllStream(stream StreamReqData) returns (stream StreamResData); // 双向流模式 } message StreamReqData{ string data = 1; } message StreamResData{ string data = 1; } 服务端\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;go_study_demo/ch2/stream_grpc_test/proto\u0026#34; \u0026#34;net\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; \u0026#34;google.golang.org/grpc\u0026#34; ) // 服务端流模式不能直接使用return返回，无法实现源源不断返回 // 所以使用res.send方法 const PORT = \u0026#34;:50052\u0026#34; type server struct { proto.UnimplementedGreeterServer } // GetStream 服务流模式 func (s *server) GetStream(req *proto.StreamReqData, res proto.Greeter_GetStreamServer) error { i := 0 for { i++ _ = res.Send(\u0026amp;proto.StreamResData{ Data: fmt.Sprintf(\u0026#34;%v\u0026#34;, time.Now().Unix()), }) time.Sleep(time.Second) if i \u0026gt; 10 { break } } return nil } // PutStream 客户端流模式 func (s *server) PutStream(res proto.Greeter_PutStreamServer) error { for { if a, err := res.Recv(); err != nil { fmt.Println(err) break } else { fmt.Println(a) } } return nil } // ALLStream 双向流模式 func (s *server) AllStream(allStr proto.Greeter_AllStreamServer) error { // 需要使用协程来双向，进行并行 wg := sync.WaitGroup{} wg.Add(2) go func() { defer wg.Done() for { data, _ := allStr.Recv() fmt.Println(data) } }() go func() { defer wg.Done() for { _ = allStr.Send(\u0026amp;proto.StreamResData{ Data: \u0026#34;我是服务器\u0026#34;, }) time.Sleep(time.Second) } }() wg.Wait() return nil } func main() { // 监听端口 lis, err := net.Listen(\u0026#34;tcp\u0026#34;, PORT) if err != nil { panic(err) } // 创建一个新的gRPC服务器实例 s := grpc.NewServer() // 注册Greeter服务到gRPC服务器 proto.RegisterGreeterServer(s, \u0026amp;server{}) // 开始通过提供的监听器lis接受传入连接，并用s来处理请求 err = s.Serve(lis) if err != nil { panic(err) } } 客户端\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;go_study_demo/ch2/stream_grpc_test/proto\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; \u0026#34;google.golang.org/grpc\u0026#34; \u0026#34;google.golang.org/grpc/credentials/insecure\u0026#34; ) func main() { conn, err := grpc.NewClient(\u0026#34;127.0.0.1:50052\u0026#34;, grpc.WithTransportCredentials(insecure.NewCredentials())) if err != nil { panic(err) } defer conn.Close() // 创建一个Greeter服务的客户端 c := proto.NewGreeterClient(conn) // 服务端流模式 // 发送StreamReqData请求并接收响应流 res, _ := c.GetStream(context.Background(), \u0026amp;proto.StreamReqData{Data: \u0026#34;天津\u0026#34;}) // 进入循环，不断从流中接收消息直到遇到错误或完成 for { a, err := res.Recv() // 接受send的信息 if err != nil { fmt.Println(err) break } fmt.Println(a.Data) } // 客户端流模式 putS, _ := c.PutStream(context.Background()) i := 0 for { i++ putS.Send(\u0026amp;proto.StreamReqData{ Data: fmt.Sprintf(\u0026#34;天津%d\u0026#34;, i), }) time.Sleep(time.Second) if i \u0026gt; 10 { break } } // 双向流模式 allStr, _ := c.AllStream(context.Background()) wg := sync.WaitGroup{} wg.Add(2) go func() { defer wg.Done() for { data, _ := allStr.Recv() fmt.Println(data) } }() go func() { defer wg.Done() for { _ = allStr.Send(\u0026amp;proto.StreamReqData{ Data: \u0026#34;我是客户端\u0026#34;, }) time.Sleep(time.Second) } }() wg.Wait() } grpc和protobuf进阶 grpc拦截器-go 功能：记录接口访问时长，验证登陆情况，等等，拦截请求，进行预处理\n1 2 3 4 5 6 s := grpc.NewServer( grpc.UnaryInterceptor(grpc_middleware.ChainUnaryServer( //otelgrpc.UnaryServerInterceptor(), interceptor.New().CacheInterceptor(), )), ) 分层微服务架构 彼此直接互不影响，版本什么各类问题互不影响\n可以同层之间调用，也可以上调用下，不可以下调上\n","date":"2024-12-23T22:12:49+08:00","permalink":"https://yuxiay.github.io/p/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E7%90%86%E8%A7%A3rpc/","title":"从0开始理解rpc"},{"content":"SQL优化与锁机制 SQL优化 通过SQL语句前加入explain进行分析\n1 explain + 正常sql语句 explain内容分析：\nexplain结构分析 id\nid值越大，先执行\nid值相同，从上往下执行\n影响行数根据影响行数从小到大\nselect_type\nPRIMARY:包含子查询SQL中的主查询（最外层）\nSUBQUERY:包含子查询SQL中的子查询（非最外层）\nSIMPLE:简单查询（不包含子查询，union）\nDERIVED:衍生查询（使用到了临时表）\n在from子查询中只有一张表\n1 explain select cr.cname from(select * from course where tid in (1,2)) 在from子查询中，如果有table union table2，则table1就是derived\ntype\n索引类型\n1 2 system\u0026gt;const\u0026gt;eq_ref\u0026gt;ref\u0026gt;range\u0026gt;index\u0026gt;all 其中：system，const只是理想情况，实际上能达到ref\u0026gt;range system:只有一条数据的系统表或衍生表，只有一条数据的主查询\nconst：仅仅能查到一条数据的SQL，用于Primary key 或 unique索引\neq_ref：唯一索引，结果多条数据，但每条数据是唯一的\nref：非唯一索引，对于每个索引键的查询，返回匹配的所有行（0，多）\nrange:检索指定范围的行，where后面是一个范围查询（between，\u0026gt; \u0026lt; \u0026gt;=, in特殊）\nindex：查询全部索引中的数据\nall：查询全部表中的数据\npossible_keys\n可能用到的索引，是一种预测，不准\n如果是NULL则无索引\nkey\n实际用到的索引\n如果是NULL则无索引\nkey_lens\n索引的长度\n作用：用于判断复合索引是否被完全使用\nut8默认一个字符3个字节\n如果可以为空则+1，如果是varchar再+2\nref\n注意：与tepe中ref区分\n作用：指明当前表所参照的字段(b.x)\n1 2 explain select ... where a.c = b.x; 其中(b.x)可以是常量，const rows\n被索引优化查询的数据个数(实际通过索引查询到的数据个数)\n1 select * from course c.teacher t where c.tid = t.tid Extra\nusing filesort:性能消耗比较大；需要“额外”一次排序（查询）常见于order by语句 1 2 3 explain select * from test02 where a1 = \u0026#39;\u0026#39; order by a2; --using filesort 小结：对于单索引，如果排序和查找是同一个字段，则不会出现using filesort 避免：where哪些字段，就order by哪些字段 1 2 3 4 alter table test02 add index idx_a1_a2_a3 (a1,a2,a3); explain select * from test02 where a1 = \u0026#39;\u0026#39; order by a3; --using filesort 小结：对于复合索引不能跨列（最佳左前缀） 避免：按照复合索引的顺序使用，不要跨列或无序使用（where和order by拼起来） using temporary:性能损耗大，用到了临时表，一般出现在group by语句中\nusing index:性能提升；索引覆盖。\n​\t原因：不读取原文件，只从索引文件中查询数据（不需要回表查询）\n​\tusing index时，会对possible_keys和key造成影响：\n​\t1.如果没有where，则索引只出现在key中\n​\t2.如果有where，则索引出现在key和possible_key中\nusing where(需要回表查询) impossible where ​\twhere子句永远为false\n优化实例 第一个简单例子\n1 2 3 4 5 6 7 create table test03( a1 int(4) not null, a2 int(4) not null, a3 int(4) not null, a4 int(4) not null, ); alter table test03 add index idx_a1_a2_a3_a4(a1,a2,a3,a4) 1 2 3 explain select a1,a2,a3,a4 from test03 where a1=1 and a2=2 and a3=3 and a4=4;\t--推荐写法 using index explain select a1,a2,a3,a4 from test03 where a4=1 and a3=2 and a2=3 and a1=4;\t--虽然编写顺序和索引顺序不一致，但是sql在真正执行前经过了sql优化器的调整，结果与上述是一致的 explain select a1,a2,a3,a4 from test03 where a1=1 and a2=2 and a4=4 order by a3;\t--以上sql用到了俩个索引a1,a2,该俩个字段不需要回表查询using index,a4需要回表查询 总结：\n如果（abcd）复合索引和使用的顺序全部一致（且不跨列使用），则复合索引全部使用，如果部分一致，则使用部分索引\nwhere和order by拼起来，不要跨列使用\n单表优化\n加索引 根据SQL解析顺便，来调整索引顺序，先解析where后解析select 索引一旦进行升级优化，需要将之前废弃索引删掉 最佳左前缀，保持索引的定义和使用的顺序一致性 将包含in的查询放到最后 多表优化\n当编写 on t.cid=c.tid 时，将数据量小的表放左边（假设t表小） 索引往哪个表加？\u0026ndash;小表驱动大表 \u0026ndash;索引建立在经常使用的字段上 一般情况，对于左外连接给左表加索引，对于右外连接给右表加索引 避免索引失效的一些原则\n复合索引，不要跨列或无序使用（最佳左前缀） 复合索引，尽量使用全索引匹配 不要在索引上进行任何操作（计算，函数，类型转换），否则索引失效，对于复合索引，如果左边失效，则右边全部失效 复合索引不能使用不等于或is null,否则自身及右侧全部失效 复合索引中如果有范围查询（\u0026gt;,\u0026lt;,in），则右侧索引全部失效（概率情况） 尽量使用索引覆盖（using index）,不会出现概率情况 like尽量以常量开头，不要以%开头，否则索引失效（using index情况下不会失效） 尽量不要使用类型转换（显示，隐式），否则都会使索引失效 尽量不要使用or，否则索引失效 一些其它优化方法\nexist和in 如果主查询的数据集大，则使用In 如果子查询的数据集大，则使用exist order by 优化 单路排序：只读取一次（全部字段），在buffer中进行排序。但此种单路排序会有一定隐患，不一定真的是单路，可能会多次IO 提高order by查询策略： 选择使用单路，双路，调整buffer容量大小 避免select * 复合索引，不要跨列使用，避免using filesort 保证全部的排序字段排序一致性（都是升序或排序） SQL排查\u0026ndash;慢查询日志\nMySQL提供的一种日志记录，用于记录MySQL中相应时间超过阈值的SQL语句（long_query_time,默认10秒）\n慢查询日志默认是关闭的；建议开发调优时打开，而最终部署时关闭\n检查是否开启了慢查询日志: show variables like '%slow_query_log';\n开启慢查询日志：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 临时开启： set global slow_query_log = 1;\t在内存中开启 exit service mysql restart 永久开启： /etc/my.cnf 中追加配置 [mysqld] slow_query_log=1 slow_query_log_file=/var/lib/mysql/localhost-slow.log 慢查询阈值： show variables like \u0026#39;%long_query_time%\u0026#39;; 临时设置阈值： set global long_query_time = 5;\t--设置完毕后不会立刻生效，需要重新登陆后才能生效 永久设置阈值： /etc/my.cnf 中追加配置 [mysqld] long_query_time=3 1 2 查询超过阈值的SQL： show global status like \u0026#39;%slow_queries\u0026#39;; 慢查询的SQL被记录在日志中，因此可以通过日志来查看具体的慢SQL 查看上述的日志文件即可\n通过mysqldumpslow工具查看慢SQL,可以通过一些过滤条件 快速查找需要定位的慢SQL\n1 2 3 4 5 mysqldumpslow --help s: 排序方式 r: 逆序 l: 锁定时间 g: 正则匹配模式 获取返回记录最多的三个SQL\n1 mysqldumpslow -s r -t 3 /var/lib/mysql/localhost-slow.log 获取访问次数最多的3个SQL\n1 mysqldumpslow -s c -t 3 /var/lib/mysql/localhost-slow.log 按照时间排序，前10条包含left join查询语句的SQL\n1 mysqldumpslow -s t -t 10 -g \u0026#34;left join\u0026#34; /var/lib/mysql/localhost-slow.log profiles分析海量数据 show profiles \u0026ndash;默认关闭\nshow variables like '%profiling%';\nset profiling = on;\nshow profiles;会记录所有 profiling打开之后的 全部查询语句所花费的时间。缺点：不够精确\n\u0026mdash; 精确分析：sql诊断\nshow profile all for query Query_Id上一步查询到的Query_Id\nshow profile cpu blockio for query Query_Id\n​\n","date":"2024-12-23T18:04:06+08:00","permalink":"https://yuxiay.github.io/p/sql%E4%BC%98%E5%8C%96%E4%B8%8E%E9%94%81%E6%9C%BA%E5%88%B6/","title":"SQL优化与锁机制"},{"content":"validator库参数校验 对参数校验是web开发中必不可少的，而手动检验重复性代码太多，所以我们引入validator库来学习参数校验\n1 2 3 4 5 6 7 8 //手动对请求参数进行业务规则校验 if len(p.Username) == 0 || len(p.Password) == 0 || len(p.RePassword) == 0 || len(p.RePassword) != len(p.Password) { zap.L().Error(\u0026#34;SignUp with invalid param\u0026#34;) c.JSON(http.StatusOK, gin.H{ \u0026#34;msg\u0026#34;: \u0026#34;请求参数有误\u0026#34;, }) return } validator库基本实例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 package main import ( \u0026#34;net/http\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; ) type SignUpParam struct { Age uint8 `json:\u0026#34;age\u0026#34; binding:\u0026#34;gte=1,lte=130\u0026#34;` Name string `json:\u0026#34;name\u0026#34; binding:\u0026#34;required\u0026#34;` Email string `json:\u0026#34;email\u0026#34; binding:\u0026#34;required,email\u0026#34;` Password string `json:\u0026#34;password\u0026#34; binding:\u0026#34;required\u0026#34;` RePassword string `json:\u0026#34;re_password\u0026#34; binding:\u0026#34;required,eqfield=Password\u0026#34;` } func main() { r := gin.Default() r.POST(\u0026#34;/signup\u0026#34;, func(c *gin.Context) { var u SignUpParam if err := c.ShouldBind(\u0026amp;u); err != nil { c.JSON(http.StatusOK, gin.H{ \u0026#34;msg\u0026#34;: err.Error(), }) return } // 保存入库等业务逻辑代码... c.JSON(http.StatusOK, \u0026#34;success\u0026#34;) }) _ = r.Run(\u0026#34;:8999\u0026#34;) } 翻译校验错误提示信息 validator库本身是支持国际化的，借助相应的语言包可以实现校验错误提示信息的自动翻译。下面的示例代码演示了如何将错误提示信息翻译成中文，翻译成其他语言的方法类似。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;github.com/gin-gonic/gin/binding\u0026#34; \u0026#34;github.com/go-playground/locales/en\u0026#34; \u0026#34;github.com/go-playground/locales/zh\u0026#34; ut \u0026#34;github.com/go-playground/universal-translator\u0026#34; \u0026#34;github.com/go-playground/validator/v10\u0026#34; enTranslations \u0026#34;github.com/go-playground/validator/v10/translations/en\u0026#34; zhTranslations \u0026#34;github.com/go-playground/validator/v10/translations/zh\u0026#34; ) // 定义一个全局翻译器T var trans ut.Translator // InitTrans 初始化翻译器 func InitTrans(locale string) (err error) { // 修改gin框架中的Validator引擎属性，实现自定制 if v, ok := binding.Validator.Engine().(*validator.Validate); ok { zhT := zh.New() // 中文翻译器 enT := en.New() // 英文翻译器 // 第一个参数是备用（fallback）的语言环境 // 后面的参数是应该支持的语言环境（支持多个） // uni := ut.New(zhT, zhT) 也是可以的 uni := ut.New(enT, zhT, enT) // locale 通常取决于 http 请求头的 \u0026#39;Accept-Language\u0026#39; var ok bool // 也可以使用 uni.FindTranslator(...) 传入多个locale进行查找 trans, ok = uni.GetTranslator(locale) if !ok { return fmt.Errorf(\u0026#34;uni.GetTranslator(%s) failed\u0026#34;, locale) } // 注册翻译器 switch locale { case \u0026#34;en\u0026#34;: err = enTranslations.RegisterDefaultTranslations(v, trans) case \u0026#34;zh\u0026#34;: err = zhTranslations.RegisterDefaultTranslations(v, trans) default: err = enTranslations.RegisterDefaultTranslations(v, trans) } return } return } type SignUpParam struct { Age uint8 `json:\u0026#34;age\u0026#34; binding:\u0026#34;gte=1,lte=130\u0026#34;` Name string `json:\u0026#34;name\u0026#34; binding:\u0026#34;required\u0026#34;` Email string `json:\u0026#34;email\u0026#34; binding:\u0026#34;required,email\u0026#34;` Password string `json:\u0026#34;password\u0026#34; binding:\u0026#34;required\u0026#34;` RePassword string `json:\u0026#34;re_password\u0026#34; binding:\u0026#34;required,eqfield=Password\u0026#34;` } func main() { if err := InitTrans(\u0026#34;zh\u0026#34;); err != nil { fmt.Printf(\u0026#34;init trans failed, err:%v\\n\u0026#34;, err) return } r := gin.Default() r.POST(\u0026#34;/signup\u0026#34;, func(c *gin.Context) { var u SignUpParam if err := c.ShouldBind(\u0026amp;u); err != nil { // 获取validator.ValidationErrors类型的errors errs, ok := err.(validator.ValidationErrors) if !ok { // 非validator.ValidationErrors类型错误直接返回 c.JSON(http.StatusOK, gin.H{ \u0026#34;msg\u0026#34;: err.Error(), }) return } // validator.ValidationErrors类型错误则进行翻译 c.JSON(http.StatusOK, gin.H{ \u0026#34;msg\u0026#34;:errs.Translate(trans), }) return } // 保存入库等具体业务逻辑代码... c.JSON(http.StatusOK, \u0026#34;success\u0026#34;) }) _ = r.Run(\u0026#34;:8999\u0026#34;) } 自定义错误提示信息的字段名 但是上述代码的翻译错误信息中的字段为结构体字段不为tag的json字段，我们通过一个函数来进行更改\n只需要在初始化翻译器的时候像下面一样添加一个获取json tag的自定义方法即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // InitTrans 初始化翻译器 func InitTrans(locale string) (err error) { // 修改gin框架中的Validator引擎属性，实现自定制 if v, ok := binding.Validator.Engine().(*validator.Validate); ok { // 注册一个获取json tag的自定义方法 v.RegisterTagNameFunc(func(fld reflect.StructField) string { name := strings.SplitN(fld.Tag.Get(\u0026#34;json\u0026#34;), \u0026#34;,\u0026#34;, 2)[0] if name == \u0026#34;-\u0026#34; { return \u0026#34;\u0026#34; } return name }) zhT := zh.New() // 中文翻译器 enT := en.New() // 英文翻译器 // 第一个参数是备用（fallback）的语言环境 // 后面的参数是应该支持的语言环境（支持多个） // uni := ut.New(zhT, zhT) 也是可以的 uni := ut.New(enT, zhT, enT) // ... liwenzhou.com ... } 1 {\u0026#34;msg\u0026#34;:{\u0026#34;SignUpParam.email\u0026#34;:\u0026#34;email必须是一个有效的邮箱\u0026#34;,\u0026#34;SignUpParam.password\u0026#34;:\u0026#34;password为必填字段\u0026#34;,\u0026#34;SignUpParam.re_password\u0026#34;:\u0026#34;re_password为必填字段\u0026#34;}} 在报错效果中，我们也不需要结构体字段，我们这时需要一个函数来去除错误信息的结构体名称字段\n这里参考https://github.com/go-playground/validator/issues/633#issuecomment-654382345提供的方法，定义一个去掉结构体名称前缀的自定义方法：\n1 2 3 4 5 6 7 func removeTopStruct(fields map[string]string) map[string]string { res := map[string]string{} for field, err := range fields { res[field[strings.Index(field, \u0026#34;.\u0026#34;)+1:]] = err } return res } 我们在代码中使用上述函数将翻译后的errors做一下处理即可：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 if err := c.ShouldBind(\u0026amp;u); err != nil { // 获取validator.ValidationErrors类型的errors errs, ok := err.(validator.ValidationErrors) if !ok { // 非validator.ValidationErrors类型错误直接返回 c.JSON(http.StatusOK, gin.H{ \u0026#34;msg\u0026#34;: err.Error(), }) return } // validator.ValidationErrors类型错误则进行翻译 // 并使用removeTopStruct函数去除字段名中的结构体名称标识 c.JSON(http.StatusOK, gin.H{ \u0026#34;msg\u0026#34;: removeTopStruct(errs.Translate(trans)), }) return } 最终效果\n1 {\u0026#34;msg\u0026#34;:{\u0026#34;email\u0026#34;:\u0026#34;email必须是一个有效的邮箱\u0026#34;,\u0026#34;password\u0026#34;:\u0026#34;password为必填字段\u0026#34;,\u0026#34;re_password\u0026#34;:\u0026#34;re_password为必填字段\u0026#34;}} 自定义结构体校验方法 上面的校验还是有点小问题，就是当涉及到一些复杂的校验规则，比如re_password字段需要与password字段的值相等这样的校验规则，我们的自定义错误提示字段名称方法就不能很好解决错误提示信息中的其他字段名称了。\n1 {\u0026#34;msg\u0026#34;:{\u0026#34;email\u0026#34;:\u0026#34;email必须是一个有效的邮箱\u0026#34;,\u0026#34;re_password\u0026#34;:\u0026#34;re_password必须等于Password\u0026#34;}} 我们为SignUpParam自定义一个校验方法如下：\n1 2 3 4 5 6 7 8 9 // SignUpParamStructLevelValidation 自定义SignUpParam结构体校验函数 func SignUpParamStructLevelValidation(sl validator.StructLevel) { su := sl.Current().Interface().(SignUpParam) if su.Password != su.RePassword { // 输出错误提示信息，最后一个参数就是传递的param sl.ReportError(su.RePassword, \u0026#34;re_password\u0026#34;, \u0026#34;RePassword\u0026#34;, \u0026#34;eqfield\u0026#34;, \u0026#34;password\u0026#34;) } } 注册一下\n1 2 3 4 5 6 7 8 9 10 11 12 func InitTrans(locale string) (err error) { // 修改gin框架中的Validator引擎属性，实现自定制 if v, ok := binding.Validator.Engine().(*validator.Validate); ok { // 为SignUpParam注册自定义校验方法 v.RegisterStructValidation(SignUpParamStructLevelValidation, SignUpParam{}) zhT := zh.New() // 中文翻译器 enT := en.New() // 英文翻译器 } ","date":"2024-12-12T21:33:24+08:00","permalink":"https://yuxiay.github.io/p/validator%E5%8F%82%E6%95%B0%E6%A3%80%E9%AA%8C/","title":"validator参数检验"},{"content":"二分搜索 在有序数组中判断数字是否存在 在有序数组中查找\u0026gt;=num的最左位置 在有序数组中查找\u0026lt;=num的最右位置 二分搜索不一定只能用在有序数组（峰值问题） \u0026ldquo;二分答案法\u0026rdquo; 二分搜索时间复杂度为O(log n) 35. 搜索插入位置 给定一个排序数组和一个目标值，在数组中找到目标值，并返回其索引。如果目标值不存在于数组中，返回它将会被按顺序插入的位置。\n请必须使用时间复杂度为 O(log n) 的算法。\n思路\n二分查找来实现，来查找他的值，经过设定每次就算没找到也返回的是它的中值\n思考：为什么没找到返回的中值也是它的插入位置呢\n因为/2默认是向下取整，也就是说，中值小于目标值的话，此时会记录可能的ans，然后继续往下查找，直到遍历结束，但是如果中值大于目标值，此时不会更新ans，如果一直大于那么ans就是插入位置，如果一开始就是大于目标值的，而且一直大于目标值，则就是最后的一次中值点的位置，最后一次left=right,mid=0,ans=0\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func searchInsert(nums []int, target int) int { n := len(nums) left, right := 0, n - 1 ans := n for left \u0026lt;= right { mid := (right - left) \u0026gt;\u0026gt; 1 + left if target \u0026lt;= nums[mid] { ans = mid right = mid - 1 } else { left = mid + 1 } } return ans } 74. 搜索二维矩阵 给你一个满足下述两条属性的 m x n 整数矩阵：\n每行中的整数从左到右按非严格递增顺序排列。 每行的第一个整数大于前一行的最后一个整数。 给你一个整数 target ，如果 target 在矩阵中，返回 true ；否则，返回 false 。\n思路\n根据二分搜索查找目标值，如果找到直接返回true，如果遍历结束没有找到直接返回false\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 func searchMatrix(matrix [][]int, target int) bool { var l, r , mid int for _, nums := range matrix { l = 0 n := len(nums) r = n-1 mid = n for l\u0026lt;=r { mid = l + (r-l)/2 if nums[mid] \u0026lt; target{ l = mid + 1 } if nums[mid]\u0026gt;target{ r = mid - 1 } if nums[mid]==target{ return true } } } return false } 34. 在排序数组中查找元素的第一个和最后一个位置 给你一个按照非递减顺序排列的整数数组 nums，和一个目标值 target。请你找出给定目标值在数组中的开始位置和结束位置。\n如果数组中不存在目标值 target，返回 [-1, -1]。\n你必须设计并实现时间复杂度为 O(log n) 的算法解决此问题\n思路\n可以通过俩次二分算法，一次查找左边界，一次查找右边界\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 // 用两个边界方法 func searchRange(nums []int, target int) []int { // 目标值开始位置：为 target 的左侧边界 start := findLeftBound(nums, target) // 如果开始位置越界 或 目标值不存在，直接返回 if start == len(nums) || nums[start] != target { return []int{-1,-1} } // 目标值结束位置：为 target 的右侧边界 end := findRightBound(nums, target) return []int{start, end} } // 寻找左侧边界的二分查找 func findLeftBound(nums []int, target int) int { left, right := 0, len(nums)-1 // note: [left, right] for left \u0026lt;= right { // note: 因为 right 是闭区间，所以可以取 = mid := left + ((right - left) \u0026gt;\u0026gt; 1) // mid = (left + right) / 2 的优化形式，防止溢出！ if nums[mid] == target { right = mid - 1 // note: 收紧右侧边界以锁定左侧边界 }else if nums[mid] \u0026lt; target { left = mid + 1 }else if nums[mid] \u0026gt; target { right = mid - 1 } } // 返回左侧边界 return left // note } // 寻找右侧边界的二分查找 func findRightBound(nums []int, target int) int { left, right := 0, len(nums)-1 for left \u0026lt;= right { mid := left + ((right - left) \u0026gt;\u0026gt; 1) if nums[mid] == target { left = mid + 1 }else if nums[mid] \u0026lt; target { left = mid + 1 }else if nums[mid] \u0026gt; target { right = mid - 1 } } // 返回右侧边界 return right } 33. 搜索旋转排序数组 整数数组 nums 按升序排列，数组中的值 互不相同 。\n在传递给函数之前，nums 在预先未知的某个下标 k（0 \u0026lt;= k \u0026lt; nums.length）上进行了 旋转，使数组变为 [nums[k], nums[k+1], ..., nums[n-1], nums[0], nums[1], ..., nums[k-1]]（下标 从 0 开始 计数）。例如， [0,1,2,4,5,6,7] 在下标 3 处经旋转后可能变为 [4,5,6,7,0,1,2] 。\n给你 旋转后 的数组 nums 和一个整数 target ，如果 nums 中存在这个目标值 target ，则返回它的下标，否则返回 -1 。\n你必须设计一个时间复杂度为 O(log n) 的算法解决此问题。\n思路\n首先，它肯定一开始是递增的，结尾也是递增的，那就在小于nums[0]大于nums[len-1]不存在，那就在nums[0]~nums[len-1]中就可能存在值小于nums[len-1]，也就是说\n目标数如果比右边小，那就再跟中值比，如果比中值大，那就在右半部分，如果比中值小，那么中值就是最新右 目标数如果比左边大，比中值小，那就在左半边，比中值大，那么中值就是最新左 ","date":"2024-12-03T22:04:06+08:00","permalink":"https://yuxiay.github.io/p/%E4%BA%8C%E5%88%86%E6%90%9C%E7%B4%A2/","title":"二分搜索"},{"content":"排序算法 选择排序 简要说明：\n​\t在in-1范围上，找到最小值并放在i位置，然后i+1n-1范围上继续，即遍历数组依次找到最小值\n代码实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 func SelectSort(args []int) []int { n := len(args) for i := 0; i \u0026lt; n-1; i++ { minIndex := i // 初始化最小值为当前起始位置 for j := i + 1; j \u0026lt; n; j++ { if args[j] \u0026lt; args[minIndex] { minIndex = j // 更新最小值索引 } } // 交换当前位置与最小值位置 args[i], args[minIndex] = args[minIndex], args[i] } return args } 冒泡排序 简要说明：\n​\t在0n的范围上，相邻位置最大的数进行俩俩交换，然后在0n-1的范围上继续\n代码实现：\n1 2 3 4 5 6 7 8 9 10 11 func BubbleSort(args []int) []int { n := len(args) for i := 0; i \u0026lt; n-1; i++ { for j := 0; j \u0026lt; n-1-i; j++ { if args[j] \u0026gt; args[j+1] { args[j], args[j+1] = args[j+1], args[j] } } } return args } 插入排序 简要说明：\n​\t在0~i的位置上已经有序，新来的数从右往左，滑倒不能再小的数进行插入，与摸牌类似\n代码实现：\n1 2 3 4 5 6 7 8 9 10 11 func InsertionSort(arr []int) { // Implementation of Insertion Sort for i := 1; i \u0026lt; len(arr); i++ { key := arr[i] j := i - 1 for j \u0026gt;= 0 \u0026amp;\u0026amp; arr[j] \u0026gt; key { arr[j+1] = arr[j] j-- } arr[j+1] = key } } ","date":"2024-12-03T22:04:06+08:00","permalink":"https://yuxiay.github.io/p/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/","title":"排序算法"},{"content":"基于cookie-session和token的认证模式 用户认证 http是一个无状态的协议，一次请求结束后，下次在发送服务器就不知道这个请求是谁发来的了（同一个IP不代表同一个用户），在web应用中，用户的认知和鉴权是非常重要的一环，实践中有多种能用方案\nCookie-session认证模式 在web应用发展初期，大部分采用基于Cookie-Session的会话管理方式，逻辑如下\n客户端使用用户名，密码进行认证 服务端验证用户名，密码正确后生成并存储Session，将SessionID通过Cookie返回给客户端 客户端访问需要认证的接口时在Cookie中携带SessionID 服务器通过SessionID查找Session并进行鉴权，返回给客户端需要的数据 基于session的方式存在多种问题\n服务器需要存储session，并且由于session需要经常快速查找，通常存储在内存或内存数据库中，同时在线用户较多时需要占用大量的服务器资源 当需要扩展时，创建session的服务器可能不是验证session的服务器，所以还要将所有的session单独存储共享 由于客户端使用cookie存储sessionID，在跨场景下需要进行兼容性处理，同时这种方式也难以防范CSRF攻击 Token认证模式 鉴于基于session的会话管理方式存在上述多个缺点，基于Token的无状态会话管理方式诞生了，所谓无状态，就是服务器可以不再存储信息，甚至是不再存储session，逻辑如下\n客户端使用用户名，密码进行认证 服务端验证用户名，密码正确后生成token返回客户端 客户端保存token，访问需要认证的接口在URL参数或HTTP Header中加入Token 服务器通过解码Token进行鉴权，返回给客户端需要的数据 基于Token会话管理方式有效解决了基于Session的会话管理方式带来的问题\n服务端不需要存储和用户鉴权有关的信息，鉴权信息会被加密到Token中，服务端只需要读取Token中包含的鉴权信息即可 避免了共享Session导致的不易扩展问题 不需要依赖Cookie，有效避免Cookie带来的CSRF攻击问题 使用CORS可以快速解决跨域问题 JWT介绍 JWT时JSON Web Token的缩写，本身是为了在网络应用环境间传递声明而执行的一种基于JSON的开放标准。JWT本身没有定义任何技术实现，它只是定义了一种基于Token的会话管理的规则，涵盖了Token需要包含的标准内容和Token的生成过程，特别适用于分布式站点的单点登陆（SSO）场景\n一个JWT Token是由三部分组成\n头部（HEADER） 负载 (PAYLOAD) 签名 (SIGNATURE) 头部和负载以JSON形式存在，这就是JWT中的JSON，三部分的内容都分别单独经过了Base64缩码，以. 拼接成一个JWT Token\nHeader JWT的Header中存储了所使用的加密算法和Token类型\n1 2 3 4 {\t\u0026#34;alg\u0026#34;: \u0026#34;HS256\u0026#34; \u0026#34;typ\u0026#34;: \u0026#34;JWT\u0026#34; } Payload Payload表示负载，也是一个JSON对象，JWT规定了7个官方字段供选用\n1 2 3 4 5 6 7 iss (issuer): 签发人 exp (expiratiaon time): 过期时间 sub (subject): 主题 aud (audience): 受众 nbf (Not Before): 生效时间 iat (Issued At): 签发时间 jti (JWT ID): 编号 除了官方字段，开发者也可以自己指定字段和内容，例如下面内容\n1 2 3 4 5 { \u0026#34;sub\u0026#34;: \u0026#34;1234567890\u0026#34; \u0026#34;name\u0026#34;: \u0026#34;John Doe\u0026#34; \u0026#34;admin\u0026#34;: true } 注意，JWT默认是不加密的，任何人都可以读到，所以不要把秘密信息放在这个部分。这个JSON对象也要使用Base64URL算法转成字符串\nSignature Signature部分是对前俩个部分的签名，防止数据篡改\n首先，需要指定一个密钥 (secret)。这个密钥只有服务器才知道，不能泄露给用户。然后，使用Header里面指定的签名算法 (默认是 HMAC SHA256)，按照下面公式产生签名\n1 HMACSHA256(base64UrlEncode(header) + \u0026#34;.\u0026#34; + base64UrlEncode(payload), secret) JWT优缺点 JWT拥有基于Token的会话管理方式所拥有的一切优势，不依赖Cookie，使得防止CSRF攻击，也能在禁用Cookie的浏览器环境中正常运行\n而JWT的最大优势是服务端不再需要存储Session，使得服务端认证鉴权业务可以方便扩展，避免存储Session所需要引入的Redis等组件，降低了系统架构的复杂度。但这也是JWT最大的劣势，由于有效期存储在Token中，JWT Token一旦签发，就会在有效期内一直可用，无法在服务端废止，当用户进行登出操作，只能依赖客户端删除掉本地存储的JWT Token，如果需要禁用用户，单纯使用JWT就无法实现\n在项目中使用JWT 我们这里使用jwt-go这个库来实现我们生成JWT和解析JWT的功能\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 package jwt import ( \u0026#34;time\u0026#34; \u0026#34;github.com/pkg/errors\u0026#34; \u0026#34;github.com/golang-jwt/jwt/v4\u0026#34; ) // MyClaims 自定义声明结构体并内嵌jwt.StandardClaims // jwt包自带的jwt.StandardClaim只包含了官方字段 // 我们这里需要额外记录一个username字段，所以要自定义结构体 // 如果想要保存更多信息，都可以添加到这个结构体中 const TokenExpireDuration = time.Hour * 2 var MySerect = []byte(\u0026#34;月亮月亮你不懂，六便士到底有多重\u0026#34;) type MyClaims struct { UserID int64 `json:\u0026#34;user_id\u0026#34;` Username string `json:\u0026#34;username\u0026#34;` jwt.RegisteredClaims } func GenToken(userID int64, username string) (string, error) { //创建一个我们自己声明的数据 claims := MyClaims{ userID, username, // 自定义字段 jwt.RegisteredClaims{ ExpiresAt: jwt.NewNumericDate(time.Now().Add(TokenExpireDuration)), Issuer: \u0026#34;bluebell\u0026#34;, // 签发人 }, } // 使用指定的签名方法创建签名对象 token := jwt.NewWithClaims(jwt.SigningMethodHS256, claims) // 使用指定的secret签名并获得完整的编码后的字符串token return token.SignedString(MySerect) } // ParseToken 解析JWT func ParseToken(tokenString string) (*MyClaims, error) { // 解析token // 如果是自定义Claim结构体则需要使用 ParseWithClaims 方法 token, err := jwt.ParseWithClaims(tokenString, \u0026amp;MyClaims{}, func(token *jwt.Token) (i interface{}, err error) { // 直接使用标准的Claim则可以直接使用Parse方法 //token, err := jwt.Parse(tokenString, func(token *jwt.Token) (i interface{}, err error) { return MySerect, nil }) if err != nil { return nil, err } // 对token对象中的Claim进行类型断言 if claims, ok := token.Claims.(*MyClaims); ok \u0026amp;\u0026amp; token.Valid { // 校验token return claims, nil } return nil, errors.New(\u0026#34;invalid token\u0026#34;) } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 const ContextUserIDKey = \u0026#34;userID\u0026#34; // JWTAuthMiddleware 基于JWT的认证中间件 func JWTAuthMiddleware() func(c *gin.Context) { return func(c *gin.Context) { // 客户端携带Token有三种方式 1.放在请求头 2.放在请求体 3.放在URI // 这里假设Token放在Header的Authorization中，并使用Bearer开头 // Authorization: Bearer xxx.xxx.xx\t/ X-TOKEN: xxx.xxx.xx // 这里的具体实现方式要依据你的实际业务情况决定 authHeader := c.Request.Header.Get(\u0026#34;Authorization\u0026#34;) if authHeader == \u0026#34;\u0026#34; { controller.ResponseError(c, controller.CodeNeedLogin) //Go语言的Gin框架中，c.Abort()是一个用于中断请求处理链的方法。 //当你在中间件或处理函数中调用c.Abort()时，它会阻止后续的中间件或处理器被调用，但是它不会停止当前处理程序的执行 //这意味着，如果在调用c.Abort()之后还有其他代码，这些代码仍然会被执行，除非跟随一个return语句来立即退出当前函数 c.Abort() return } // 按空格分割 parts := strings.SplitN(authHeader, \u0026#34; \u0026#34;, 2) if !(len(parts) == 2 \u0026amp;\u0026amp; parts[0] == \u0026#34;Bearer\u0026#34;) { controller.ResponseError(c, controller.CodeInvalidAuth) c.Abort() return } //第二种方式可用直接从这里开始，将前面调整取X-Token // parts[1]是获取到的tokenString，我们使用之前定义好的解析JWT的函数来解析它 mc, err := jwt.ParseToken(parts[1]) if err != nil { controller.ResponseError(c, controller.CodeInvalidAuth) c.Abort() return } // 将当前请求的userID信息保存到请求的上下文c上 c.Set(ContextUserIDKey, mc.UserID) c.Next() // 后续的处理函数可以用过c.Get(ContextUserIDKey)来获取当前请求的用户信息 } } ","date":"2024-11-20T19:07:26+08:00","permalink":"https://yuxiay.github.io/p/jwt%E7%94%A8%E6%88%B7%E8%AE%A4%E8%AF%81/","title":"JWT用户认证"},{"content":"pprof Go语言内置了获取程序的运行数据的工具，包括以下两个标准库：\nruntime/pprof：采集工具型应用运行数据进行分析 net/http/pprof：采集服务型应用运行时数据进行分析 net/http/pprof源码上也是根据runtime/pprof进行编写\npprof开启后，每隔一段时间（10ms）就会收集下当前的堆栈信息，获取各个函数占用的CPU以及内存资源；最后通过对这些采样数据进行分析，形成一个性能分析报告。\n注意，我们只应该在性能测试的时候才在代码中引入pprof\n作用 pprof 是 Go 语言中分析程序运行性能的工具，它能提供各种性能数据：\n类型 描述 allocs 内存分配情况的采样信息 blocks 阻塞操作情况的采样信息 threadcreate 系统线程创建情况的采样信息 goroutine 当前所有协程的堆栈信息 heap 堆上内存使用情况的采用信息 mutex 锁争用情况的采样信息 cmdline 显示程序启动命令以及参数 profile CPU占用情况采样信息 trace 程序运行跟踪信息 工具型 runtime/pprof包中预制了一些profile：\ncpu：cpu使用情况 memory（heap）：内存使用情况 threadcreate: os线程使用情况 goroutine：所有当前运行的goroutine堆栈跟踪信息 block：goroutine阻塞等待的情况 mutex：锁竞争的情况（一般是由于锁竞争导致cpu未被充分利用） 开启CPU性能分析：\n1 pprof.StartCPUProfile(w io.Writer) 停止CPU性能分析：\n1 pprof.StopCPUProfile() 应用执行结束后，就会生成一个文件，保存了我们的 CPU profiling 数据。得到采样数据之后，使用go tool pprof工具进行CPU性能分析。\n记录程序的堆栈信息\n1 pprof.WriteHeapProfile(w io.Writer) 得到采样数据之后，使用go tool pprof工具进行内存性能分析。\ngo tool pprof默认是使用-inuse_space进行统计，还可以使用-inuse-objects查看分配对象的数量。\n案例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 package main import ( \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;runtime/pprof\u0026#34; \u0026#34;time\u0026#34; ) // 一段有问题的代码 func logicCode() { var c chan int for { select { case v := \u0026lt;-c: fmt.Printf(\u0026#34;recv from chan, value:%v\\n\u0026#34;, v) default: } } } func main() { // 两个标志位: 是否开启CPU和内存的标志位 var isCPUPprof bool var isMemPprof bool // 命令行参数定义 flag.BoolVar(\u0026amp;isCPUPprof, \u0026#34;cpu\u0026#34;, false, \u0026#34;turn cpu pprof on\u0026#34;) flag.BoolVar(\u0026amp;isMemPprof, \u0026#34;mem\u0026#34;, false, \u0026#34;turn mem pprof on\u0026#34;) flag.Parse() // 是否开启CPUprofile if isCPUPprof { // 在当前路径建立一个文件 file, err := os.Create(\u0026#34;./cpu.pprof\u0026#34;) if err != nil { fmt.Printf(\u0026#34;create cpu pprof failed, err:%v\\n\u0026#34;, err) return } // 往文件中记录CPU proofile信息 pprof.StartCPUProfile(file) defer func() { pprof.StopCPUProfile() file.Close() }() } for i := 0; i \u0026lt; 8; i++ { go logicCode() } // 程序跑20s time.Sleep(20 * time.Second) // 是否开启内存profile if isMemPprof { file, err := os.Create(\u0026#34;./mem.pprof\u0026#34;) if err != nil { fmt.Printf(\u0026#34;create mem pprof failed, err:%v\\n\u0026#34;, err) return } pprof.WriteHeapProfile(file) file.Close() } } 1 go run .\\main.go -cpu 等待20s，生成cpu.pprof\n1 2 3 4 5 6 go tool pprof cpu.pprof Type: cpu Time: Jan 7, 2023 at 12:51am (CST) Duration: 20.30s, Total samples = 100.47s (494.88%) Entering interactive mode (type \u0026#34;help\u0026#34; for commands, \u0026#34;o\u0026#34; for options) (pprof) Duration：程序执行时间。 Total samples：采样时间，比如采样时间100s，有10核，每核采样10s 输入top 5来显示占用CPU前5的函数：\n1 2 3 4 5 6 7 8 9 10 (pprof) top 5 Showing nodes accounting for 98.19s, 97.73% of 100.47s total Dropped 44 nodes (cum \u0026lt;= 0.50s) Showing top 5 nodes out of 9 flat flat% sum% cum cum% 49.38s 49.15% 49.15% 49.54s 49.31% runtime.chanrecv 33.20s 33.04% 82.19% 83.07s 82.68% runtime.selectnbrecv 14.76s 14.69% 96.88% 98.16s 97.70% main.logicCode 0.46s 0.46% 97.34% 0.76s 0.76% runtime.findrunnable 0.39s 0.39% 97.73% 2.19s 2.18% runtime.schedule flat：当前函数占用CPU的耗时 flat%：:当前函数占用CPU的耗时百分比 sun%：函数占用CPU的耗时累计百分比 cum：当前函数加上调用当前函数的函数占用CPU的总耗时 cum%：当前函数加上调用当前函数的函数占用CPU的总耗时百分比 最后一列：函数名称 可以看出，main.logicCode占用的cpu最多\n输入list logicCode来查看具体的信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 (pprof) list logicCode Total: 100.47s ROUTINE ======================== main.logicCode in D:\\go\\project\\test_project\\ip-get\\pprof_test\\main.go 14.76s 98.16s (flat, cum) 97.70% of Total . . 7: \u0026#34;runtime/pprof\u0026#34; . . 8: \u0026#34;time\u0026#34; . . 9:) . . 10: . . 11:// 一段有问题的代码 . 120ms 12:func logicCode() { . . 13: var c chan int . . 14: for { . . 15: select { 14.76s 98.04s 16: case v := \u0026lt;-c: . . 17: fmt.Printf(\u0026#34;recv from chan, value:%v\\n\u0026#34;, v) . . 18: default: . . 19: . . 20: } . . 21: } (pprof) 很明显得出：case v := \u0026lt;-c:这行代码有问题，当然代码的问题也很明显，因为default无内容，channel中又没有任何信息，会一直卡在这处代码，所以解决方案，default加一些信息即可\n1 2 3 4 5 6 7 8 9 10 11 func logicCode() { var c chan int for { select { case v := \u0026lt;-c: fmt.Printf(\u0026#34;recv from chan, value:%v\\n\u0026#34;, v) default: time.Sleep(time.Second * 2) } } } 重新生成，发现问题消失\n1.3.3 命令说明 web：浏览器会弹出各个函数之间的调用图，以及内存的之间的关系 top：按指标大小列出前n个函数，比如内存是按内存占用多少，CPU是按执行时间多少。 list：查看某个函数的代码，以及该函数每行代码的指标信息，如果函数名不明确，会进行模糊匹配，比如list main会列出main.main和runtime.main traces：打印所有调用栈，以及调用栈的指标信息。使用方式为traces+函数名（模糊匹配）。 1.3.4 图形化 地址：https://graphviz.gitlab.io/\n安装完后，在pprof命令中输入svg或者gif\n图中各个方块的大小也代表 CPU 占用的情况，方块越大说明占用 CPU 时间越长。\n线条代表了函数的调用链，线条越粗，代表指向的函数消耗了越多的资源。反之亦然。\n线条的样式代表了调用关系。实线代表直接调用；虚线代表中间少了几个节点；带有inline字段表示该函数被内联进了调用方。\n除了这种方式，目前推荐的是pprof，也就是说pprof就已经集成了这样的功能，包括火焰图等，\n地址：https://github.com/google/pprof\n1 go tool pprof -http=\u0026#34;:8881\u0026#34; .\\cpu.pprof 火焰图就看长短即可。每一个方块代表的是函数，长短就是执行时间，调用关系是从上到下。颜色无特殊含义。\n比较 1 go tool pprof -base .\\mem1.pprof .\\mem.pprof 假设我们已经通过命令行得到profile1与profile2,使用go tool pprof -base profile1 profile2，便可以以profile1为基础，得出profile2在profile1之上出现了哪些变化。通过两个时间切片的比较，我们可以清晰的了解到，两个时间节点之中发生的变化，方便我们定位问题\n总结步骤 通过监控平台监测到内存或cpu问题。 通过浏览器方式大致判断是哪些可能的问题。 通过命令行方式抓取几个时间点的profile 使用web命令查看函数调用图 使用top 、traces、list 命令定位问题 如果出现了goroutine泄漏或者内存泄漏等随着时间持续增长的问题，go tool pprof -base比较两个不同时间点的状态更方便我们定位问题。 服务型 在Web服务中，我们使用服务型进行性能分析\n注：也是基于工具型来实现的\n如果使用的gin框架，则可以直接使用github.com/gin-contrib/pprof，在代码中通过以下命令注册pprof相关路由。\n1 pprof.Register(router) 以gin框架为例，使用方式和上面一样，无非profile文件变成了一个http连接\n1 go tool pprof http://localhost/debug/pprof/heap 案例 模拟内存泄漏，一般内存泄漏大多是goroutine泄漏\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 func main() { r := gin.Default() r.Use(midd.RequestLog()) //路由 router.InitRouter(r) r.StaticFS(\u0026#34;/upload\u0026#34;, http.Dir(\u0026#34;upload\u0026#34;)) //开启pprof pprof.Register(r) r.GET(\u0026#34;/mem\u0026#34;, func(c *gin.Context) { // 业务代码运行 outCh := make(chan int) // 每秒起10个goroutine，goroutine会阻塞，不释放内存 tick := time.Tick(time.Second / 10) i := 0 for range tick { i++ fmt.Println(i) alloc1(outCh) // 不停的有goruntine因为outCh堵塞，无法释放 } }) srv.Run(r, config.C.SC.Name, config.C.SC.Addr, nil) } // 一个外层函数 func alloc1(outCh chan\u0026lt;- int) { go alloc2(outCh) } // 一个内层函数 func alloc2(outCh chan\u0026lt;- int) { func() { defer fmt.Println(\u0026#34;alloc-fm exit\u0026#34;) // 分配内存，假用一下 buf := make([]byte, 1024*1024*10) _ = len(buf) fmt.Println(\u0026#34;alloc done\u0026#34;) outCh \u0026lt;- 0 }() } 1 2 3 4 5 6 7 8 9 10 11 12 13 go tool pprof http://localhost/debug/pprof/goroutine Type: goroutine Time: Jan 8, 2023 at 11:22am (CST) Entering interactive mode (type \u0026#34;help\u0026#34; for commands, \u0026#34;o\u0026#34; for options) (pprof) top Showing nodes accounting for 751, 99.73% of 753 total Dropped 64 nodes (cum \u0026lt;= 3) Showing top 10 nodes out of 19 flat flat% sum% cum cum% 751 99.73% 99.73% 751 99.73% runtime.gopark 0 0% 99.73% 4 0.53% io.ReadFull 0 0% 99.73% 723 96.02% main.alloc2 0 0% 99.73% 723 96.02% main.alloc2.func1 可以看到有751个goroutine处于挂起（runtime.gopark）状态，即goroutine泄漏。\n1 2 3 4 5 6 7 8 9 (pprof) traces Type: goroutine Time: Jan 8, 2023 at 11:22am (CST) -----------+------------------------------------------------------- 723 runtime.gopark runtime.chansend runtime.chansend1 main.alloc2.func1 main.alloc2 trace命令,可以查看栈调用信息，就能很快的找到问题在于main包中alloc2方法的匿名函数出现了channel send堵塞。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 (pprof) list main.alloc2 Total: 753 ROUTINE ======================== main.alloc2 in D:\\go\\project\\test_project\\project-api\\main.go 0 723 (flat, cum) 96.02% of Total . . 49: buf := make([]byte, 1024*1024*10) . . 50: _ = len(buf) . . 51: fmt.Println(\u0026#34;alloc done\u0026#34;) . . 52: . . 53: outCh \u0026lt;- 0 . 723 54: }() . . 55:} ROUTINE ======================== main.alloc2.func1 in D:\\go\\project\\test_project\\project-api\\main.go 0 723 (flat, cum) 96.02% of Total . . 48: // 分配内存，假用一下 . . 49: buf := make([]byte, 1024*1024*10) . . 50: _ = len(buf) . . 51: fmt.Println(\u0026#34;alloc done\u0026#34;) . . 52: . 723 53: outCh \u0026lt;- 0 . . 54: }() . . 55:} 最终定位是outCh \u0026lt;- 0发生了问题，当然原因是channel只发，未取 造成了阻塞\n","date":"2024-11-02T16:09:16+08:00","permalink":"https://yuxiay.github.io/p/pprof%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/","title":"pprof性能分析"},{"content":"go并发编程 协程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) // go并发编程 // 协程，内存占用小（2k），切换快 // go语言没有线程，go语言诞生之后只有协程可用 -goroutine 非常方便 // 主协程 // 主协程执行完，子协程会结束 func main() { // 主死随从 // 匿名函数启动goroutine // 1.闭包 // 2.for循环问题 for循环的时候，每个变量会重用 // 每次for循环时，i变量会被重用，当我进行到第二轮for循环时候，这个i就变了 for i := 0; i \u0026lt; 100; i++ { go func(i int) { fmt.Println(i) }(i) } fmt.Println(\u0026#34;main\u0026#34;) time.Sleep(1 * time.Second) } go gmp调度原理 Go语言的GMP调度模型是其并发能力的核心，通过高效管理Goroutine（G）、操作系统线程（M）和逻辑处理器（P）的协作，实现了轻量级线程的高效调度。以下是对其原理的详细解析：\nGMP组件角色 Goroutine（G） 轻量级用户态线程，由Go运行时管理，栈初始仅几KB，动态扩展。通过go关键字创建，开销远小于OS线程。 Machine（M） 对应操作系统线程，由内核调度。M必须绑定一个P才能执行G，否则休眠。阻塞的系统调用会触发M与P解绑，避免资源浪费。 Processor（P） 逻辑处理器，管理G的上下文环境（如本地运行队列）。数量默认等于CPU核心数（由GOMAXPROCS设置），决定并行执行的G数量。 调度流程 G的创建与分配 新G优先放入当前P的本地队列（避免锁竞争）；若本地队列满（容量256），则放入全局队列。 M执行G M需绑定P后，从P的本地队列获取G执行。若本地队列空，按以下顺序获取任务： 从全局队列取（需加锁，每次取一批）。 从其他P的本地队列窃取一半任务（Work-Stealing机制）。 阻塞处理 系统调用阻塞：M与P解绑，P被其他空闲M接管继续执行。原M执行完系统调用后，尝试获取P，若失败则将G放入全局队列，自身休眠。 Channel/锁阻塞：G进入等待队列，M释放P执行其他G。G被唤醒后重新放入P的队列。 抢占式调度 协作式抢占：在函数调用时插入检查点（如栈扩容），触发调度。 信号式抢占（Go 1.14+）：sysmon监控线程检测运行超过10ms的G，发送信号强制中断，实现抢占。 关键机制 Work-Stealing 空闲P从其他P的本地队列窃取任务，平衡负载，避免部分P闲置。 Hand Off机制 M阻塞时释放P，由其他M接管，确保CPU资源不被浪费。 全局队列与本地队列 本地队列无锁操作，提升性能。 全局队列作为备用，解决任务分配不均问题。 互斥锁 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) // 锁，资源竞争 var total int var wg sync.WaitGroup // 锁能复制吗 本质是结构体是可以复制的，但是复制后就失去了锁的效果 var lock sync.Mutex func add() { defer wg.Done() for i := 0; i \u0026lt; 1000000; i++ { lock.Lock() total += i // 竞争 lock.Unlock() } } func sub() { defer wg.Done() for i := 0; i \u0026lt; 1000000; i++ { lock.Lock() total -= i lock.Unlock() } } func main() { wg.Add(2) go add() go sub() wg.Wait() fmt.Println(total) } // 资源竞争，当加载a的值时，如果俩个都同时加载值，那么a的值将变得不可确定 // 这时我们可以用锁来进行串行运算 如果只是想用简单的加减运算逻辑可以使用atomic包，进行原子操作\n1 atomic.AddInt64(\u0026amp;total, 1) 读写锁 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) // 锁本质上是将并行的代码串行化了，使用lock肯定会影响性能 // 即使是设计锁，那么也应该尽量保证并行 // 我们有俩组协程，其中一组负责写数据，另一组负责读数据 // web系统中绝大多数场景是读多写少 // 虽然有多个goroutine，但是仔细分析我们发现，读协程是可以并发的，读和写应该串行，读和读之间也不应该并行 // 读写锁 func main() { var rwlock sync.RWMutex // 使主函数是在协程结束时结束 var wg sync.WaitGroup wg.Add(11) // 写的goroutine go func() { defer wg.Done() time.Sleep(1 * time.Second) rwlock.Lock() // 加写锁，写锁会防止别的写锁获取和读锁获取 defer rwlock.Unlock() fmt.Println(\u0026#34;get write\u0026#34;) time.Sleep(1 * time.Second) }() // 读的goroutine for i := 0; i \u0026lt; 10; i++ { go func() { defer wg.Done() for { rwlock.RLock() // 加读锁，读锁不会阻止别人的读 time.Sleep(1 * time.Microsecond) fmt.Println(\u0026#34;get read\u0026#34;) rwlock.RUnlock() } }() } wg.Wait() } goroutine之间的通信 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 package main import \u0026#34;fmt\u0026#34; // goroutine之间的通信方式 /* 不要通过共享内存来通信，而要通过通信来实现内存共享 php, python, java, 多线程编程的时候，俩个goroutine之间的通信最常用是一个全局 也会提供消息队列的机制\t消费者与生产者之间的关系 channel 再加上语法糖让使用channel更加简单 */ /* go 中channel的应用场景： 1. 消息传递， 消息过滤 2. 信号广播 3. 事件订阅和广播 4. 任务分发 5. 结果汇总 6. 并发控制 7. 同步异步 */ func main() { var msg1 chan string var msg2 chan string // channel的初始化值 如果为0的话，你放进去会阻塞 // 有缓冲channel\t适用于消费者与生产者之间的通信 msg1 = make(chan string, 2) // 无缓冲channel\t适用于通知，B要第一时间知道A是否已经完成 msg2 = make(chan string, 0) // go有一种happen-before机制，可以保障无缓冲channel的写高于读进行操作 go func(msg chan string) { data := \u0026lt;-msg fmt.Println(data) }(msg2) // 放值到channel中 msg2 \u0026lt;- \u0026#34;hello\u0026#34; msg1 \u0026lt;- \u0026#34;world\u0026#34; // 取值 data := \u0026lt;-msg1 fmt.Println(data) } // 出现死锁 // 1. waitgroup 如果缺少了done调用 // 2. 无缓冲的channel 也容易出现 for range 对channel进行遍历 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { var msg chan int msg = make(chan int, 2) go func(msg chan int) { for data := range msg { fmt.Println(data) } fmt.Println(\u0026#34;all done\u0026#34;) }(msg) // 放值到channel中 msg \u0026lt;- 1 msg \u0026lt;- 2 close(msg) // 与其他语言有很大区别，可以关闭channel msg \u0026lt;- 3 // 已经关闭的channel不能再放值了 d := \u0026lt;-msg // 已经关闭的channel可以再取值 fmt.Println(d) time.Sleep(time.Second * 10) } 单向channel的应用场景 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) // 单向channel // 默认情况下，channel是双向的 // 但是，我们经常一个channel作为参数进行传递，希望对方是单向使用 func producer(out chan\u0026lt;- int) { for i := 0; i \u0026lt; 10; i++ { out \u0026lt;- i * i } close(out) } func consumer(in \u0026lt;-chan int) { for v := range in { fmt.Println(v) } } func main() { //var ch1 chan int // 双向channel //var ch2 chan\u0026lt;- float64 // 单向channel，只能写入float64数据 //var ch3 \u0026lt;- chan bool\t// 单向channel，只能读取 // 可以将双向channel改为俩个单向channel // 不能将单向channel转为双向 //c := make(chan int, 3) //var send chan\u0026lt;- int = c\t// send-only //var read \u0026lt;-chan int = c\t// recv-only //send \u0026lt;- 1 //\u0026lt;-read ch := make(chan int) // 可以内部自动转换为单向 go producer(ch) go consumer(ch) time.Sleep(time.Second * 5) } channel的死锁问题 channel满了，写就阻塞，空了，读就阻塞 阻塞之后会交出cpu，去执行其它协程，希望其它协程帮自己解除阻塞 如果阻塞发生在main协程里，并且没有其它子协程可以执行，那就会报死锁 如果阻塞发生在子协程里，就不会发生死锁，因为至少mani协程是一个值得等待的，会一直阻塞下去 小练习题 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) /* 使用俩个goroutine交替打印序列，一个goroutine打印数字，另外一个goroutine打印字母 */ var number, letter = make(chan bool), make(chan bool) func printNumber() { i := 0 for { \u0026lt;-number fmt.Printf(\u0026#34;%d%d\u0026#34;, i, i+1) i = i + 2 letter \u0026lt;- true } } func printLetter() { i := 0 str := \u0026#34;ABCDEFGHIJKLMNOPQRSTUVWSYZ\u0026#34; for { \u0026lt;-letter if i \u0026gt;= len(str) { return } fmt.Printf(str[i : i+2]) i = i + 2 number \u0026lt;- true } } func main() { go printNumber() go printLetter() number \u0026lt;- true time.Sleep(time.Second * 15) } select 监控goroutine运行 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) // 监控goroutine的运行 // select 类似于switch case语句，但是select的功能和我们操作linux里面提供的io的select，poll，epoll // select主要作用于多个channel // 现在有个需求，我们现在有俩个goroutine都在执行，但是呢，我在主goroutine中，当某一个执行完成以后，这个时候我会立马知道这个 var done = make(chan struct{}) // channel是多线程安全的 func g1(ch chan struct{}) { time.Sleep(time.Second) ch \u0026lt;- struct{}{} } func g2(ch chan struct{}) { time.Sleep(time.Second) ch \u0026lt;- struct{}{} } func main() { g1Ch := make(chan struct{}) g2Ch := make(chan struct{}) go g1(g1Ch) go g2(g2Ch) // 我要监控多个channel，任何一个channel返回都知道 // 1. 某一个分支就绪了就执行该分支 // 2. 如果两个都就绪了，随机的, 目的是防止饥饿 timer := time.NewTimer(time.Second * 5) for { select { case \u0026lt;-g1Ch: fmt.Println(\u0026#34;g1 done\u0026#34;) case \u0026lt;-g2Ch: fmt.Println(\u0026#34;g2 done\u0026#34;) case \u0026lt;-timer.C: fmt.Println(\u0026#34;timeout\u0026#34;) return } } } 通过context解决goroutine信息传递问题 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) // 通过context解决goroutine信息传递 // 渐进式的方式 // 需求：有一个goroutine监控cpu的信息 // 需求: 我们可以主动退出监控程序 var wg sync.WaitGroup var stop = make(chan struct{}) func cpuInfo(ctx context.Context) { // 这里能拿到一个请求的id fmt.Printf(\u0026#34;tracid: %s\\r\\n\u0026#34;, ctx.Value(\u0026#34;traceid\u0026#34;)) defer wg.Done() for { select { case \u0026lt;-ctx.Done(): fmt.Println(\u0026#34;退出cpu监控\u0026#34;) return default: time.Sleep(2 * time.Second) fmt.Println(\u0026#34;cpu信息\u0026#34;) } } } func main() { wg.Add(1) // context包提供了三种函数，WithCancel, WithTimeout, WithValue // 如果你的goroutine，函数中，如果希望被控制，超时，传值，但是我不希望影响我原来的接口信息时候，函数参数中第一个参数就尽量的要加上一个ctx // 1. WithCancel 主动cancel //ctx1, cancel1 := context.WithCancel(context.Background()) // 子context调用父context的cancel也有效 //ctx2, _ := context.WithCancel(context.Background()) //go cpuInfo(ctx2) //cancel1() // 2. timeout 主动超时 ctx, _ := context.WithTimeout(context.Background(), 6*time.Second) // 3. WithDeadline 在时间点cancel // 4. WithValue valueCtx := context.WithValue(ctx, \u0026#34;traceid\u0026#34;, \u0026#34;123\u0026#34;) go cpuInfo(valueCtx) wg.Wait() fmt.Println(\u0026#34;监控完成\u0026#34;) } ","date":"2024-10-23T21:32:56+08:00","permalink":"https://yuxiay.github.io/p/go%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/","title":"go并发编程"},{"content":"gin-swagger库 步骤：\n按照swagger要求给接口代码添加声明式注释 使用swag工具扫描代码自动生成API接口文档 使用gin-swagger渲染在线接口文档页面 步骤一 在程序入口main函数上以注释的方式写下项目相关介绍信息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package main // @title 这里写标题 // @version 1.0 // @description 这里写描述信息 // @termsOfService http://swagger.io/terms/ // @contact.name 这里写联系人信息 // @contact.url http://www.swagger.io/support // @contact.email support@swagger.io // @license.name Apache 2.0 // @license.url http://www.apache.org/licenses/LICENSE-2.0.html // @host 这里写接口服务的host // @BasePath 这里写base path func main() { r := gin.New() // liwenzhou.com ... r.Run() } 在你代码中处理请求的接口函数（通常位于controller层）按如下方式写上注释：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // GetPostListHandler2 升级版帖子列表接口 // @Summary 升级版帖子列表接口 // @Description 可按社区按时间或分数排序查询帖子列表接口 // @Tags 帖子相关接口 // @Accept application/json // @Produce application/json // @Param Authorization header string false \u0026#34;Bearer 用户令牌\u0026#34; // @Param object query models.ParamPostList false \u0026#34;查询参数\u0026#34; // @Security ApiKeyAuth // @Success 200 {object} _ResponsePostList // @Router /posts2 [get] func GetPostListHandler2(c *gin.Context) { // GET请求参数(query string)：/api/v1/posts2?page=1\u0026amp;size=10\u0026amp;order=time // 初始化结构体时指定初始参数 p := \u0026amp;models.ParamPostList{ Page: 1, Size: 10, Order: models.OrderTime, } if err := c.ShouldBindQuery(p); err != nil { zap.L().Error(\u0026#34;GetPostListHandler2 with invalid params\u0026#34;, zap.Error(err)) ResponseError(c, CodeInvalidParam) return } data, err := logic.GetPostListNew(p) // 获取数据 if err != nil { zap.L().Error(\u0026#34;logic.GetPostList() failed\u0026#34;, zap.Error(err)) ResponseError(c, CodeServerBusy) return } ResponseSuccess(c, data) // 返回响应 } 在你代码中处理请求的接口函数（通常位于controller层）按如下方式写上注释：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // GetPostListHandler2 升级版帖子列表接口 // @Summary 升级版帖子列表接口 // @Description 可按社区按时间或分数排序查询帖子列表接口 // @Tags 帖子相关接口 // @Accept application/json // @Produce application/json // @Param Authorization header string false \u0026#34;Bearer 用户令牌\u0026#34; // @Param object query models.ParamPostList false \u0026#34;查询参数\u0026#34; // @Security ApiKeyAuth // @Success 200 {object} _ResponsePostList // @Router /posts2 [get] func GetPostListHandler2(c *gin.Context) { // GET请求参数(query string)：/api/v1/posts2?page=1\u0026amp;size=10\u0026amp;order=time // 初始化结构体时指定初始参数 p := \u0026amp;models.ParamPostList{ Page: 1, Size: 10, Order: models.OrderTime, } if err := c.ShouldBindQuery(p); err != nil { zap.L().Error(\u0026#34;GetPostListHandler2 with invalid params\u0026#34;, zap.Error(err)) ResponseError(c, CodeInvalidParam) return } data, err := logic.GetPostListNew(p) // 获取数据 if err != nil { zap.L().Error(\u0026#34;logic.GetPostList() failed\u0026#34;, zap.Error(err)) ResponseError(c, CodeServerBusy) return } ResponseSuccess(c, data) // 返回响应 } 上面注释中参数类型使用了object，models.ParamPostList具体定义如下：\n1 2 3 4 5 6 7 8 9 // bluebell/models/params.go // ParamPostList 获取帖子列表query string参数 type ParamPostList struct { CommunityID int64 `json:\u0026#34;community_id\u0026#34; form:\u0026#34;community_id\u0026#34;` // 可以为空 Page int64 `json:\u0026#34;page\u0026#34; form:\u0026#34;page\u0026#34; example:\u0026#34;1\u0026#34;` // 页码 Size int64 `json:\u0026#34;size\u0026#34; form:\u0026#34;size\u0026#34; example:\u0026#34;10\u0026#34;` // 每页数据量 Order string `json:\u0026#34;order\u0026#34; form:\u0026#34;order\u0026#34; example:\u0026#34;score\u0026#34;` // 排序依据 } 响应数据类型也使用的object，我个人习惯在controller层专门定义一个docs_models.go文件来存储文档中使用的响应数据model。\n1 2 3 4 5 6 7 8 // bluebell/controller/docs_models.go // _ResponsePostList 帖子列表接口响应数据 type _ResponsePostList struct { Code ResCode `json:\u0026#34;code\u0026#34;` // 业务响应状态码 Message string `json:\u0026#34;message\u0026#34;` // 提示信息 Data []*models.ApiPostDetail `json:\u0026#34;data\u0026#34;` // 数据 } 第二步：生成接口文档数据 1. 安装 swag 工具 bash\n复制\n1 2 3 4 5 6 # 安装swag命令行工具（需提前配置GOPATH环境变量） go install github.com/swaggo/swag/cmd/swag@latest # 验证安装 swag -v # 输出示例: swag version v1.8.12 2. 生成Swagger文档 在项目根目录执行命令：\nbash\n复制\n1 swag init --parseDependency --parseInternal --parseDepth 3 参数说明：\n--parseDependency：解析依赖包中的注释（如自定义模型） --parseInternal：解析内部依赖 --parseDepth 3：解析目录深度（确保扫描到所有控制器） 生成结果：\n1 2 3 4 ├── docs/ │ ├── docs.go # 文档结构代码 │ ├── swagger.json # OpenAPI规范文件 │ └── swagger.yaml # YAML格式文档 第三步：集成gin-swagger 1. 导入依赖 在 main.go 中添加：\ngo\n复制\n1 2 3 4 5 6 import ( // 其他导入... _ \u0026#34;your_project/docs\u0026#34; // 替换为你的项目路径（如github.com/yourname/bluebell/docs） ginSwagger \u0026#34;github.com/swaggo/gin-swagger\u0026#34; \u0026#34;github.com/swaggo/gin-swagger/swaggerFiles\u0026#34; ) 2. 添加Swagger路由 在Gin路由初始化代码前添加：\ngo\n复制\n1 2 3 4 5 6 7 8 // main.go的main函数中 r := gin.New() // 添加Swagger路由 r.GET(\u0026#34;/swagger/*any\u0026#34;, ginSwagger.WrapHandler(swaggerFiles.Handler)) // 其他路由注册... r.Run(\u0026#34;:8080\u0026#34;) 验证文档生成 1. 启动服务 bash\n复制\n1 go run main.go 2. 访问Swagger UI 浏览器打开： http://localhost:8080/swagger/index.html\n","date":"2024-10-13T22:30:21+08:00","permalink":"https://yuxiay.github.io/p/gin-swagger%E5%BA%93/","title":"gin-swagger库"},{"content":"nowflake算法介绍 雪花算法是由64位整数组成的分布式ID，性能高\n第一位 占用1bit，其值始终为0，无实际意义\n时间戳 占用41位，单位为毫米，可以从开始时间一直持续下去，总共可以容纳约69年时间\n工作机器id 占用10位，为项目的工作机器，其中高位5bit是数据中心ID，低位5bit是工作节点ID\n序列号 占用12bit，用来记录同毫秒内产生不同的id号\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/bwmarrin/snowflake\u0026#34; ) var node *snowflake.Node // init函数 初始化全局node节点 // startTime 开始时间 machineID 工作节点 func Init(startTime string, machineID int64) (err error) { var st time.Time //获取开始时间的时间戳 st, err = time.Parse(\u0026#34;2006-01-02 15:04:05\u0026#34;, startTime) if err != nil { return } //初始化开始时间 snowflake.Epoch = st.UnixNano() / 1000000 //拿到机器id，生成node节点 node, err = snowflake.NewNode(machineID) return } // 将节点转化为64位int类型 func Gen() int64 { return node.Generate().Int64() } func main() { err := Init(\u0026#34;2020-07-01\u0026#34;, 1) if err != nil { fmt.Println(\u0026#34;init failed, err: %v\\n\u0026#34;, err) } id := Gen() fmt.Println(id) } ","date":"2024-10-02T21:14:10+08:00","permalink":"https://yuxiay.github.io/p/%E9%9B%AA%E8%8A%B1%E7%AE%97%E6%B3%95/","title":"雪花算法"},{"content":" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 func Init(mode string) (err error) { //读取配置中的logger信息,并进行配置 //Lumberjack Logger采用以下属性作为输入: // //Filename: 日志文件的位置 //MaxSize：在进行切割之前，日志文件的最大大小（以MB为单位） //MaxBackups：保留旧文件的最大个数 //MaxAges：保留旧文件的最大天数 //Compress：是否压缩/归档旧文件 writeSynced := getLogWriter( settings.Conf.LogConfig.Filename, settings.Conf.LogConfig.MaxSize, settings.Conf.LogConfig.MaxBackups, settings.Conf.LogConfig.MaxAge, ) //这是一个 zapcore.Encoder 类型的参数，负责将日志级别的数据（如日志消息、键值对等）编码成字节流。 encoder := getEncoder() //定义一下日志级别 //Zap 支持多种日志级别，包括 Debug、Info、Warn、Error、DPanic、Panic 和 Fatal var l = new(zapcore.Level) err = l.UnmarshalText([]byte(settings.Conf.LogConfig.Level)) if err != nil { fmt.Printf(\u0026#34;UnmarshalText err:%v\\n\u0026#34;, err) return } var core zapcore.Core if mode == \u0026#34;dev\u0026#34; { //开发模式，日主输出到终端 consoleEncoder := zapcore.NewConsoleEncoder(zap.NewDevelopmentEncoderConfig()) //日志输出位置，定为俩个 core = zapcore.NewTee( //日志文件 zapcore.NewCore(encoder, writeSynced, l), //打印到终端 zapcore.NewCore(consoleEncoder, zapcore.Lock(os.Stdout), zapcore.DebugLevel), ) } else { core = zapcore.NewCore(encoder, writeSynced, l) } //创建一个新的zap日志记录器 lg := zap.New(core, zap.AddCaller()) //替换zap库中全局的logger //在主函数中使用zap.L()调用全局的logger zap.ReplaceGlobals(lg) return } //将其更改为josn编码模式，将日志改为已读的年月日形式 func getEncoder() zapcore.Encoder { encoderConfig := zap.NewProductionEncoderConfig() encoderConfig.EncodeTime = zapcore.ISO8601TimeEncoder encoderConfig.TimeKey = \u0026#34;time\u0026#34; encoderConfig.EncodeLevel = zapcore.CapitalLevelEncoder encoderConfig.EncodeDuration = zapcore.SecondsDurationEncoder encoderConfig.EncodeCaller = zapcore.ShortCallerEncoder return zapcore.NewJSONEncoder(encoderConfig) } //保存配置信息，并返回一个日志生成器 func getLogWriter(filename string, maxSize, maxBackup, maxAge int) zapcore.WriteSyncer { lumberJackLogger := \u0026amp;lumberjack.Logger{ Filename: filename, MaxSize: maxSize, MaxBackups: maxBackup, MaxAge: maxAge, } return zapcore.AddSync(lumberJackLogger) } // GinLogger 接收gin框架默认的日志 func GinLogger() gin.HandlerFunc { return func(c *gin.Context) { start := time.Now() path := c.Request.URL.Path query := c.Request.URL.RawQuery c.Next() cost := time.Since(start) zap.L().Info(path, zap.Int(\u0026#34;status\u0026#34;, c.Writer.Status()), zap.String(\u0026#34;method\u0026#34;, c.Request.Method), zap.String(\u0026#34;path\u0026#34;, path), zap.String(\u0026#34;query\u0026#34;, query), zap.String(\u0026#34;ip\u0026#34;, c.ClientIP()), zap.String(\u0026#34;user-agent\u0026#34;, c.Request.UserAgent()), zap.String(\u0026#34;errors\u0026#34;, c.Errors.ByType(gin.ErrorTypePrivate).String()), zap.Duration(\u0026#34;cost\u0026#34;, cost), ) } } // GinRecovery recover掉项目可能出现的panic，并使用zap记录相关日志 func GinRecovery(stack bool) gin.HandlerFunc { return func(c *gin.Context) { defer func() { if err := recover(); err != nil { // Check for a broken connection, as it is not really a // condition that warrants a panic stack trace. var brokenPipe bool if ne, ok := err.(*net.OpError); ok { if se, ok := ne.Err.(*os.SyscallError); ok { if strings.Contains(strings.ToLower(se.Error()), \u0026#34;broken pipe\u0026#34;) || strings.Contains(strings.ToLower(se.Error()), \u0026#34;connection reset by peer\u0026#34;) { brokenPipe = true } } } httpRequest, _ := httputil.DumpRequest(c.Request, false) if brokenPipe { zap.L().Error(c.Request.URL.Path, zap.Any(\u0026#34;error\u0026#34;, err), zap.String(\u0026#34;request\u0026#34;, string(httpRequest)), ) // If the connection is dead, we can\u0026#39;t write a status to it. c.Error(err.(error)) // nolint: errcheck c.Abort() return } if stack { zap.L().Error(\u0026#34;[Recovery from panic]\u0026#34;, zap.Any(\u0026#34;error\u0026#34;, err), zap.String(\u0026#34;request\u0026#34;, string(httpRequest)), zap.String(\u0026#34;stack\u0026#34;, string(debug.Stack())), ) } else { zap.L().Error(\u0026#34;[Recovery from panic]\u0026#34;, zap.Any(\u0026#34;error\u0026#34;, err), zap.String(\u0026#34;request\u0026#34;, string(httpRequest)), ) } c.AbortWithStatus(http.StatusInternalServerError) } }() c.Next() } } ","date":"2024-09-03T20:04:06+08:00","permalink":"https://yuxiay.github.io/p/zap%E6%97%A5%E5%BF%97%E5%BA%93/","title":"zap日志库"}]